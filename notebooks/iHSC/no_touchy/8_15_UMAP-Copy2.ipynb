{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45c7154-1c06-40e9-bac3-4e88f26a2955",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b944c3f0-63e7-4f23-bc4a-f52b96a77eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1\n",
      "C2\n",
      "C3\n",
      "C4\n",
      "C5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import os\n",
    "import gc\n",
    "from importlib import reload\n",
    "print(\"C1\")\n",
    "\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import load_dataset\n",
    "from geneformer import EmbExtractor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "print(\"C2\")\n",
    "\n",
    "#classifer tools\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"C3\")\n",
    "\n",
    "sns.set_style('white')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, load_from_disk, load_dataset\n",
    "import geneformer\n",
    "\n",
    "from datetime import datetime\n",
    "print(\"C4\")\n",
    "DEFAULT_NAME_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_name_id_dict.pkl\"\n",
    "DEFAULT_TOKEN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/token_dictionary.pkl\"\n",
    "DEFAULT_MEDIAN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_median_dictionary.pkl\"\n",
    "\n",
    "sns.set_style('white')\n",
    "torch.cuda.empty_cache()\n",
    "print(\"C5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260bda0f-29e5-44a5-ad6a-88d2334e2bb6",
   "metadata": {},
   "source": [
    "# Importing the anndata files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a620b0f-b45c-486c-96b2-bddd2b4f14eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original obs contents:\n",
      "                                   input_ids   cell_type         dataset  \\\n",
      "0  [16345  9009 13048 ...  9332 13451  5456]  fibroblast  TS_Vasculature   \n",
      "1  [12119  9190 16876 ... 11232  1132  1022]  fibroblast  TS_Vasculature   \n",
      "2  [ 3878  9009  4115 ...  4697 10362 12098]  fibroblast  TS_Vasculature   \n",
      "3  [ 3878 16916 18367 ... 15470  3946  2153]  fibroblast  TS_Vasculature   \n",
      "4  [ 6196 16916 10920 ...  7629 10148 17125]  fibroblast  TS_Vasculature   \n",
      "\n",
      "  length      ignore standardized_cell_type  broad_type __index_level_0__  \\\n",
      "0   2048  fibroblast             Fibroblast  fibroblast            109770   \n",
      "1   2048  fibroblast             Fibroblast  fibroblast            109771   \n",
      "2   2048  fibroblast             Fibroblast  fibroblast            109774   \n",
      "3   2048  fibroblast             Fibroblast  fibroblast            109776   \n",
      "4   2048  fibroblast             Fibroblast  fibroblast            109777   \n",
      "\n",
      "  cell_id recipe     type  \n",
      "0  cell_1    raw  initial  \n",
      "1  cell_2    raw  initial  \n",
      "2  cell_3    raw  initial  \n",
      "3  cell_4    raw  initial  \n",
      "4  cell_5    raw  initial  \n",
      "Contents of obs_backup after creation:\n",
      "                                   input_ids   cell_type         dataset  \\\n",
      "0  [16345  9009 13048 ...  9332 13451  5456]  fibroblast  TS_Vasculature   \n",
      "1  [12119  9190 16876 ... 11232  1132  1022]  fibroblast  TS_Vasculature   \n",
      "2  [ 3878  9009  4115 ...  4697 10362 12098]  fibroblast  TS_Vasculature   \n",
      "3  [ 3878 16916 18367 ... 15470  3946  2153]  fibroblast  TS_Vasculature   \n",
      "4  [ 6196 16916 10920 ...  7629 10148 17125]  fibroblast  TS_Vasculature   \n",
      "\n",
      "  length      ignore standardized_cell_type  broad_type __index_level_0__  \\\n",
      "0   2048  fibroblast             Fibroblast  fibroblast            109770   \n",
      "1   2048  fibroblast             Fibroblast  fibroblast            109771   \n",
      "2   2048  fibroblast             Fibroblast  fibroblast            109774   \n",
      "3   2048  fibroblast             Fibroblast  fibroblast            109776   \n",
      "4   2048  fibroblast             Fibroblast  fibroblast            109777   \n",
      "\n",
      "  cell_id recipe     type  \n",
      "0  cell_1    raw  initial  \n",
      "1  cell_2    raw  initial  \n",
      "2  cell_3    raw  initial  \n",
      "3  cell_4    raw  initial  \n",
      "4  cell_5    raw  initial  \n",
      "Contents of cleared obs:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n",
      "Contents of obs_backup after clearing original obs:\n",
      "                                   input_ids   cell_type         dataset  \\\n",
      "0  [16345  9009 13048 ...  9332 13451  5456]  fibroblast  TS_Vasculature   \n",
      "1  [12119  9190 16876 ... 11232  1132  1022]  fibroblast  TS_Vasculature   \n",
      "2  [ 3878  9009  4115 ...  4697 10362 12098]  fibroblast  TS_Vasculature   \n",
      "3  [ 3878 16916 18367 ... 15470  3946  2153]  fibroblast  TS_Vasculature   \n",
      "4  [ 6196 16916 10920 ...  7629 10148 17125]  fibroblast  TS_Vasculature   \n",
      "\n",
      "  length      ignore standardized_cell_type  broad_type __index_level_0__  \\\n",
      "0   2048  fibroblast             Fibroblast  fibroblast            109770   \n",
      "1   2048  fibroblast             Fibroblast  fibroblast            109771   \n",
      "2   2048  fibroblast             Fibroblast  fibroblast            109774   \n",
      "3   2048  fibroblast             Fibroblast  fibroblast            109776   \n",
      "4   2048  fibroblast             Fibroblast  fibroblast            109777   \n",
      "\n",
      "  cell_id recipe     type  \n",
      "0  cell_1    raw  initial  \n",
      "1  cell_2    raw  initial  \n",
      "2  cell_3    raw  initial  \n",
      "3  cell_4    raw  initial  \n",
      "4  cell_5    raw  initial  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliven/miniconda3/envs/geneformer2/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/tmp/ipykernel_300948/1375448826.py:17: ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.\n",
      "  initial_adata.uns['obs_backup'] = initial_adata.obs.copy()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_name</th>\n",
       "      <th>recipe_number</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10412</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_10413</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_5050</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_10634</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_9363</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_4065</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_3120</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_5671</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_3537</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_13947</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10993</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cell_10994</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       recipe_name  recipe_number     cell_id     type\n",
       "10412          NaN            NaN  cell_10413  initial\n",
       "5049           NaN            NaN   cell_5050  initial\n",
       "10633          NaN            NaN  cell_10634  initial\n",
       "9362           NaN            NaN   cell_9363  initial\n",
       "4064           NaN            NaN   cell_4065  initial\n",
       "3119           NaN            NaN   cell_3120  initial\n",
       "5670           NaN            NaN   cell_5671  initial\n",
       "3536           NaN            NaN   cell_3537  initial\n",
       "13946          NaN            NaN  cell_13947  initial\n",
       "10993          NaN            NaN  cell_10994  initial"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Iniitla cells\n",
    "# Just pick from a random file where they were copied (the first half ish of them have them still in original). Then filter by type\n",
    "\n",
    "harvest_file_path = '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/originals/2024-07-31_03-49-01_job_number_22.h5ad'\n",
    "harvest_file_adata = ad.read_h5ad(harvest_file_path)\n",
    "initial_adata = harvest_file_adata[harvest_file_adata.obs['type'] == 'initial']\n",
    "\n",
    "\n",
    "# get adata up and working\n",
    "# Ensure hsc_adata is already defined and populated with data\n",
    "\n",
    "# 1. Check the contents of the original obs\n",
    "print(\"Original obs contents:\")\n",
    "print(initial_adata.obs.head())\n",
    "\n",
    "# 2. Create the backup\n",
    "initial_adata.uns['obs_backup'] = initial_adata.obs.copy()\n",
    "\n",
    "# 3. Verify the backup was created correctly\n",
    "print(\"Contents of obs_backup after creation:\")\n",
    "print(initial_adata.uns['obs_backup'].head())\n",
    "\n",
    "# 4. Clear the original obs\n",
    "initial_adata.obs = pd.DataFrame(index=initial_adata.obs.index)\n",
    "\n",
    "# 5. Check the contents of the cleared obs and the backup\n",
    "print(\"Contents of cleared obs:\")\n",
    "print(initial_adata.obs.head())\n",
    "\n",
    "print(\"Contents of obs_backup after clearing original obs:\")\n",
    "print(initial_adata.uns['obs_backup'].head())\n",
    "\n",
    "\n",
    "\n",
    "#initial_adata.obs['kmeans_cluster'] = initial_kmeans.labels_\n",
    "initial_adata.obs['recipe_name'] = np.nan\n",
    "initial_adata.obs['recipe_number'] = np.nan\n",
    "initial_adata.obs['cell_id'] = initial_adata.uns['obs_backup']['cell_id']\n",
    "initial_adata.obs['type'] = 'initial'\n",
    "\n",
    "\n",
    "\n",
    "initial_adata.obs.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cb581c-0908-4e10-b55b-0fffe45de788",
   "metadata": {},
   "source": [
    "# ISP Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89825c4-087d-4800-81bc-bd6045e008f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file = '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/originals/' + '2024-07-31_03-17-04_job_number_12.h5ad'\n",
    "# reprog_centroid_adata_wid = ad.read_h5ad(reprog_wid_path)\n",
    "# # this is not actually written into the file idk if we care? \n",
    "# reprog_centroid_adata_wid.obs['type'] = 'reprogrammed'\n",
    "# reprog_centroid_adata_wid.obs['cluster_number'] = range(1, len(reprog_centroid_adata_wid.obs) + 1)\n",
    "# kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "\n",
    "# # Fit KMeans to the DataFrame (make sure to use the feature columns only)\n",
    "# reprog_centroid_adata['kmeans'] = kmeans.fit_predict(reprog_centroid_adata)\n",
    "\n",
    "# reprog_centroid_adata_wid.obs.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83b218-13a7-4a35-9d8a-0f31cabfab29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5370c1b-be65-47e9-a546-9614a150a5de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# import pandas as pd\n",
    "# import anndata as ad\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Initialize an empty AnnData object (This will be replaced by actual data)\n",
    "# reprog_centroid_adata = ad.AnnData()\n",
    "\n",
    "# all_cluster_labels = []\n",
    "# all_cell_id_labels = []\n",
    "# all_recipe_name_labels = []\n",
    "# all_recipe_num_labels = []\n",
    "\n",
    "# def ten_choose_five():\n",
    "#     gene_list = [\n",
    "#         'GATA2', \n",
    "#         'GFI1B', \n",
    "#         'FOS', \n",
    "#         'STAT5A',\n",
    "#         'REL',\n",
    "#         'FOSB',\n",
    "#         'IKZF1',\n",
    "#         'RUNX3',\n",
    "#         'MEF2C',\n",
    "#         'ETV6',\n",
    "#     ]\n",
    "#     len_sublist = 5\n",
    "#     sublists = list(combinations(gene_list, len_sublist))\n",
    "    \n",
    "#     df = pd.DataFrame({\n",
    "#         'recipe_iteration': range(1, len(sublists) + 1),\n",
    "#         'recipe_list': [list(sublist) for sublist in sublists]\n",
    "#     })\n",
    "#     return df\n",
    "\n",
    "# pert_df = ten_choose_five()\n",
    "# pert_df['recipe_list'] = pert_df['recipe_list'].apply(lambda x: ';'.join(x))\n",
    "# pert_dict = pert_df.set_index('recipe_list')['recipe_iteration'].to_dict()\n",
    "\n",
    "# print(\"Going to read in \")\n",
    "# print(file)\n",
    "# one_recipe_adata = ad.read_h5ad(file)\n",
    "# print(one_recipe_adata.obs.columns)\n",
    "\n",
    "# one_recipe_adata = one_recipe_adata[one_recipe_adata.obs['type'] == 'reprogrammed']\n",
    "\n",
    "# # Perform k-means clustering\n",
    "# kmeans = KMeans(n_clusters=10, random_state=0).fit(one_recipe_adata.X)\n",
    "# one_recipe_adata.obs['kmeans_clusters'] = kmeans.labels_\n",
    "\n",
    "# # Collect data for the AnnData object\n",
    "# all_cell_id_labels = one_recipe_adata.obs['cell_id'].tolist()\n",
    "# all_cluster_labels = one_recipe_adata.obs['kmeans_clusters'].tolist()\n",
    "\n",
    "# recipe_names_this_file = one_recipe_adata.obs['recipe'].unique()\n",
    "# if len(recipe_names_this_file) == 1:\n",
    "#     recipe_as_string = recipe_names_this_file[0]\n",
    "#     recipe_as_list = recipe_as_string.split(';')\n",
    "#     print(f'The unique value is: {recipe_as_list}')\n",
    "#     recipe_num = pert_dict[recipe_as_string]\n",
    "#     print(recipe_num)\n",
    "# else:\n",
    "#     print('Error: There are multiple unique values or no values in the column.')\n",
    "\n",
    "# # Prepare the AnnData object with all cells\n",
    "# reprog_centroid_adata = ad.AnnData(X=one_recipe_adata.X)\n",
    "# reprog_centroid_adata.obs['kmeans_cluster'] = all_cluster_labels\n",
    "# reprog_centroid_adata.obs['cell_id'] = all_cell_id_labels\n",
    "# reprog_centroid_adata.obs['recipe_name'] = [recipe_as_string] * len(all_cluster_labels)\n",
    "# reprog_centroid_adata.obs['recipe_number'] = [recipe_num] * len(all_cluster_labels)\n",
    "\n",
    "# print(\"All cell data and kmeans_cluster values have been added to reprog_centroid_adata.\")\n",
    "# print(reprog_centroid_adata.obs.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9ddc5a-4dfd-476b-855d-98254218493f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# import pandas as pd\n",
    "# import anndata as ad\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# import os\n",
    "\n",
    "# def ten_choose_five():\n",
    "#     gene_list = [\n",
    "#         'GATA2', \n",
    "#         'GFI1B', \n",
    "#         'FOS', \n",
    "#         'STAT5A',\n",
    "#         'REL',\n",
    "#         'FOSB',\n",
    "#         'IKZF1',\n",
    "#         'RUNX3',\n",
    "#         'MEF2C',\n",
    "#         'ETV6',\n",
    "#     ]\n",
    "#     len_sublist = 5\n",
    "#     sublists = list(combinations(gene_list, len_sublist))\n",
    "    \n",
    "#     df = pd.DataFrame({\n",
    "#         'recipe_iteration': range(1, len(sublists) + 1),\n",
    "#         'recipe_list': [list(sublist) for sublist in sublists]\n",
    "#     })\n",
    "#     return df\n",
    "\n",
    "# pert_df = ten_choose_five()\n",
    "# pert_df['recipe_list'] = pert_df['recipe_list'].apply(lambda x: ';'.join(x))\n",
    "# pert_dict = pert_df.set_index('recipe_list')['recipe_iteration'].to_dict()\n",
    "\n",
    "# # List of files to process\n",
    "# file_list = ['/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-03-23_job_number_89.h5ad','/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-01-47_job_number_88.h5ad']  # Replace with actual file names\n",
    "\n",
    "# # Initialize a list to collect data\n",
    "# all_data = []\n",
    "\n",
    "# for file in file_list:\n",
    "#     print(\"Going to read in \", file)\n",
    "#     one_recipe_adata = ad.read_h5ad(file)\n",
    "#     print(one_recipe_adata.obs.columns)\n",
    "\n",
    "#     one_recipe_adata = one_recipe_adata[one_recipe_adata.obs['type'] == 'reprogrammed']\n",
    "\n",
    "#     # Perform K-means clustering\n",
    "#     kmeans = KMeans(n_clusters=10, random_state=0).fit(one_recipe_adata.X)\n",
    "#     one_recipe_adata.obs['kmeans_clusters'] = kmeans.labels_\n",
    "\n",
    "#     # Extract recipe number\n",
    "#     recipe_names_this_file = one_recipe_adata.obs['recipe'].unique()\n",
    "#     if len(recipe_names_this_file) == 1:\n",
    "#         recipe_as_string = recipe_names_this_file[0]\n",
    "#         recipe_num = pert_dict.get(recipe_as_string, None)\n",
    "#         if recipe_num is None:\n",
    "#             print(f\"Recipe number not found for {recipe_as_string}\")\n",
    "#             continue\n",
    "#     else:\n",
    "#         print('Error: There are multiple unique values or no values in the column.')\n",
    "#         continue\n",
    "\n",
    "#     # Combine recipe number with kmeans cluster number\n",
    "#     one_recipe_adata.obs['kmeans'] = one_recipe_adata.obs['kmeans_clusters'].apply(\n",
    "#         lambda x: int(f\"{recipe_num}{x}\")\n",
    "#     )\n",
    "\n",
    "#     # Collect data\n",
    "#     all_data.append(one_recipe_adata)\n",
    "\n",
    "# # Concatenate all AnnData objects\n",
    "# combined_adata = ad.concat(all_data, join='outer')\n",
    "\n",
    "# print(\"Cluster counts:\")\n",
    "# combined_adata.obs.sample(20)\n",
    "\n",
    "# # she works b\"h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2319495b-cd2f-4599-8ebf-e4e707856d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok here's where we have to be careful.  going back to an old version of the file to find where reprog_centroid_adata_wid was made, and if there's composite of the original cells. checking in turbo first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e88763d-34ac-4c8e-8e33-a1cce3542230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-44_job_number_1.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-45_job_number_2.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-53_job_number_3.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-49_job_number_4.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-45-28_job_number_5.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-55_job_number_6.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-45-23_job_number_7.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_02-44-57_job_number_8.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-16-56_job_number_9.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-16-48_job_number_10.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-16-43_job_number_11.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-17-04_job_number_12.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-16-52_job_number_13.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-16-44_job_number_14.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-17-52_job_number_15.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-18-00_job_number_16.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-27-40_job_number_17.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-31-58_job_number_18.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-48-31_job_number_19.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-48-37_job_number_20.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-48-37_job_number_21.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-49-01_job_number_22.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-49-07_job_number_23.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-49-44_job_number_24.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-50-17_job_number_25.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-50-52_job_number_26.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-51-51_job_number_27.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_03-56-06_job_number_28.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-21-03_job_number_29.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-21-21_job_number_30.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-21-34_job_number_31.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-21-41_job_number_32.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-21-34_job_number_33.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-22-21_job_number_34.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-23-32_job_number_35.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-24-16_job_number_36.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-16-31_job_number_37.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-20-20_job_number_38.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-40-49_job_number_39.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-44-24_job_number_40.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-46-22_job_number_41.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-46-12_job_number_42.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-46-42_job_number_43.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-53-19_job_number_44.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-53-52_job_number_45.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-54-39_job_number_46.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-54-53_job_number_47.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_04-56-01_job_number_48.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-05-35_job_number_49.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-15-26_job_number_50.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-10-22_job_number_51.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-10-07_job_number_52.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-10-55_job_number_53.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-24-48_job_number_54.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-25-08_job_number_55.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-25-48_job_number_56.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-25-46_job_number_57.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-26-49_job_number_58.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-29-54_job_number_59.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-33-52_job_number_60.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-34-28_job_number_61.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-35-00_job_number_62.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-46-31_job_number_63.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-56-45_job_number_64.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-57-15_job_number_65.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-57-58_job_number_66.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-57-43_job_number_67.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-59-04_job_number_68.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-02-51_job_number_69.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-07-19_job_number_70.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-20-04_job_number_71.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-14-21_job_number_72.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-29-31_job_number_73.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-30-17_job_number_74.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-31-23_job_number_75.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-32-17_job_number_76.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-34-03_job_number_77.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-36-41_job_number_78.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-40-10_job_number_79.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-38-03_job_number_80.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-52-01_job_number_81.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-00-36_job_number_82.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-01-47_job_number_83.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-03-40_job_number_84.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-03-52_job_number_85.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-06-36_job_number_86.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-09-06_job_number_87.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-01-47_job_number_88.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-03-23_job_number_89.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-12-49_job_number_90.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-24-29_job_number_91.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-31-35_job_number_92.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-25-45_job_number_93.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-32-54_job_number_94.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-27-17_job_number_95.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-35-50_job_number_96.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-34-58_job_number_97.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-39-11_job_number_98.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-41-20_job_number_99.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-45-19_job_number_100.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-57-04_job_number_101.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-50-00_job_number_102.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_07-51-42_job_number_103.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-03-04_job_number_104.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-04-28_job_number_105.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-06-33_job_number_106.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-09-17_job_number_107.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-11-16_job_number_108.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-13-55_job_number_109.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-17-49_job_number_110.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-14-03_job_number_111.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-15-34_job_number_112.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-29-33_job_number_113.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-34-55_job_number_114.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-35-56_job_number_115.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-38-08_job_number_116.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-41-28_job_number_117.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-42-51_job_number_118.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-45-35_job_number_119.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-38-05_job_number_120.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_08-39-21_job_number_121.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-01-18_job_number_122.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-06-16_job_number_123.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-07-15_job_number_124.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-01-51_job_number_125.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-09-26_job_number_126.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-03-44_job_number_127.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-13-27_job_number_128.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-14-52_job_number_129.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-17-24_job_number_130.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-18-08_job_number_131.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-25-25_job_number_132.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-25-30_job_number_133.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-28-20_job_number_134.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-37-17_job_number_135.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-38-12_job_number_136.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-40-42_job_number_137.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-44-48_job_number_138.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-46-17_job_number_139.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-48-45_job_number_140.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-41-54_job_number_141.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-49-17_job_number_142.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_09-57-00_job_number_143.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-09-44_job_number_144.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-10-07_job_number_145.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-13-03_job_number_146.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-06-44_job_number_147.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-15-45_job_number_148.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-17-15_job_number_149.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-13-12_job_number_150.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-17-37_job_number_151.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-28-03_job_number_152.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-30-52_job_number_153.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-41-09_job_number_154.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-41-14_job_number_155.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-37-16_job_number_156.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-44-48_job_number_157.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-32-15_job_number_158.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-33-21_job_number_159.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-43-57_job_number_160.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-48-21_job_number_161.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-49-22_job_number_162.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-49-51_job_number_163.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-57-22_job_number_164.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-57-26_job_number_165.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_10-59-50_job_number_166.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-00-52_job_number_167.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-03-47_job_number_168.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-04-51_job_number_169.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-16-11_job_number_170.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-19-59_job_number_171.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-18-56_job_number_172.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-21-50_job_number_173.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-31-28_job_number_174.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-35-36_job_number_175.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-37-14_job_number_176.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-43-17_job_number_177.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-47-23_job_number_178.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-47-26_job_number_179.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-45-00_job_number_180.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-49-26_job_number_181.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-50-59_job_number_182.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-52-45_job_number_183.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-58-34_job_number_184.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-57-00_job_number_185.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_11-58-59_job_number_186.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-07-41_job_number_187.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-08-31_job_number_188.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-12-30_job_number_189.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-04-08_job_number_190.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-10-43_job_number_191.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-13-14_job_number_192.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-16-48_job_number_193.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-18-24_job_number_194.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-26-19_job_number_195.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-27-17_job_number_196.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-27-05_job_number_197.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-29-46_job_number_198.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-29-16_job_number_199.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-32-38_job_number_200.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-31-28_job_number_201.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-31-32_job_number_202.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-43-03_job_number_203.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-42-52_job_number_204.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-44-10_job_number_205.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-45-31_job_number_206.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-46-40_job_number_207.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-44-03_job_number_208.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-44-38_job_number_209.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-48-13_job_number_210.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-58-26_job_number_211.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-59-23_job_number_212.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-57-24_job_number_213.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-56-28_job_number_214.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-00-29_job_number_215.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_12-57-02_job_number_216.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-01-31_job_number_217.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-03-05_job_number_218.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-03-51_job_number_219.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-08-41_job_number_220.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-09-07_job_number_221.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-09-36_job_number_222.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-14-24_job_number_223.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-15-16_job_number_224.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-16-25_job_number_225.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-17-28_job_number_226.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-19-00_job_number_227.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-19-59_job_number_228.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-21-12_job_number_229.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-21-32_job_number_230.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-22-10_job_number_231.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-30-47_job_number_232.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-31-20_job_number_233.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-32-44_job_number_234.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-33-44_job_number_235.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-35-27_job_number_236.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-36-08_job_number_237.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-33-33_job_number_238.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-34-04_job_number_239.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-34-39_job_number_240.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-47-06_job_number_241.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-47-45_job_number_242.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-52-04_job_number_243.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-49-44_job_number_244.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-47-10_job_number_245.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-53-37_job_number_246.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_13-52-07_job_number_247.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_14-03-09_job_number_248.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_14-04-57_job_number_249.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_14-05-42_job_number_250.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_14-07-39_job_number_251.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_14-05-19_job_number_252.h5ad',\n",
       " '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_15-38-49_job_number_252.h5ad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def list_reprogramming_jobs(directory, start_job_number, end_job_number):\n",
    "    \"\"\"\n",
    "    List and sort files in the given directory by job number within the specified range.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory containing the files.\n",
    "    start_job_number (int): The starting job number.\n",
    "    end_job_number (int): The ending job number.\n",
    "\n",
    "    Returns:\n",
    "    list: A sorted list of file names within the specified job number range.\n",
    "    \"\"\"\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Define a regex pattern to extract job numbers\n",
    "    pattern = re.compile(r'_job_number_(\\d+)\\.h5ad$')\n",
    "\n",
    "    # Create a list of tuples (job_number, file_name)\n",
    "    files_with_job_numbers = []\n",
    "    for file in files:\n",
    "        match = pattern.search(file)\n",
    "        if match:\n",
    "            job_number = int(match.group(1))\n",
    "            if start_job_number <= job_number <= end_job_number:\n",
    "                files_with_job_numbers.append((job_number, file))\n",
    "\n",
    "    # Sort files by job number\n",
    "    files_with_job_numbers.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Extract sorted file names\n",
    "    sorted_files = [file for _, file in files_with_job_numbers]\n",
    "\n",
    "    return sorted_files\n",
    "\n",
    "\n",
    "\n",
    "directory = '/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/'\n",
    "files_in_directory = list_reprogramming_jobs(directory, 1, 252)\n",
    "files_in_directory = [os.path.join(directory,file) for file in files_in_directory]\n",
    "files_in_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03efce8a-9604-4aef-abed-18eb33296aca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98e510-a038-4a49-a958-db834f5589ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "def ten_choose_five():\n",
    "    gene_list = [\n",
    "        'GATA2', \n",
    "        'GFI1B', \n",
    "        'FOS', \n",
    "        'STAT5A',\n",
    "        'REL',\n",
    "        'FOSB',\n",
    "        'IKZF1',\n",
    "        'RUNX3',\n",
    "        'MEF2C',\n",
    "        'ETV6',\n",
    "    ]\n",
    "    len_sublist = 5\n",
    "    sublists = list(combinations(gene_list, len_sublist))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'recipe_iteration': range(1, len(sublists) + 1),\n",
    "        'recipe_list': [list(sublist) for sublist in sublists]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "pert_df = ten_choose_five()\n",
    "pert_df['recipe_list'] = pert_df['recipe_list'].apply(lambda x: ';'.join(x))\n",
    "pert_dict = pert_df.set_index('recipe_list')['recipe_iteration'].to_dict()\n",
    "\n",
    "# List of files to process\n",
    "  # Replace with actual file names\n",
    "\n",
    "# Initialize a list to collect data\n",
    "all_data = []\n",
    "\n",
    "for file in files_in_directory:\n",
    "    print(\"Going to read in \", file)\n",
    "    one_recipe_adata = ad.read_h5ad(file)\n",
    "    print(one_recipe_adata.obs.columns)\n",
    "\n",
    "    one_recipe_adata = one_recipe_adata[one_recipe_adata.obs['type'] == 'reprogrammed']\n",
    "\n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=10, random_state=0).fit(one_recipe_adata.X)\n",
    "    one_recipe_adata.obs['kmeans_clusters'] = kmeans.labels_\n",
    "\n",
    "    # Extract recipe number\n",
    "    recipe_names_this_file = one_recipe_adata.obs['recipe'].unique()\n",
    "    if len(recipe_names_this_file) == 1:\n",
    "        recipe_as_string = recipe_names_this_file[0]\n",
    "        recipe_num = pert_dict.get(recipe_as_string, None)\n",
    "        if recipe_num is None:\n",
    "            print(f\"Recipe number not found for {recipe_as_string}\")\n",
    "            continue\n",
    "    else:\n",
    "        print('Error: There are multiple unique values or no values in the column.')\n",
    "        continue\n",
    "\n",
    "    # Combine recipe number with kmeans cluster number\n",
    "    one_recipe_adata.obs['kmeans'] = one_recipe_adata.obs['kmeans_clusters'].apply(\n",
    "        lambda x: int(f\"{recipe_num}{x}\")\n",
    "    )\n",
    "\n",
    "    # Collect data\n",
    "    all_data.append(one_recipe_adata)\n",
    "\n",
    "# Concatenate all AnnData objects\n",
    "combined_adata = ad.concat(all_data, join='outer')\n",
    "\n",
    "# she works b\"h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f28ee-ee99-48ab-8295-540519d3c7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4afd91-48fe-4f5f-9365-2ab69aa4490e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and we pray \n",
    "combined_adata.obs.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39564350-4cdc-475a-8405-68bcc255457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# youve gotta delete the duplicate 252 again girlpop\n",
    "# Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# Get the rows where 'kmeans_clusters' is equal to 252\n",
    "rows_with_252 = (combined_adata.obs['kmeans'] >= 2520)\n",
    "\n",
    "# Count the number of rows with kmeans_clusters equal to 252\n",
    "num_rows_252 = rows_with_252.sum()\n",
    "\n",
    "print(f\"Number of rows with 'kmeans' equal to 252: {num_rows_252}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ec22c-d6d5-4c49-962e-000f1aba9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (combined_adata.obs['kmeans'] >= 1830) | (combined_adata.obs['kmeans'] <= 1839) \n",
    "# Filter the DataFrame based on the mask\n",
    "test_obs = combined_adata.obs[mask]\n",
    "\n",
    "# Step 2: Count the number of unique rows\n",
    "num_unique_rows = test_obs.shape[0]\n",
    "num_unique_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22596f-b41b-44a5-b126-d932aa0c86a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of all rows with kmeans >= 2520 doesn't solve it. the other dataframe with < 2520 is a whack job. on the one hand,\n",
    "# it seems like each bin (binned together by recipe) has 15308 in it with the exception of 0-9 bc we started cluster number at 10 \n",
    "# instead of 00.\n",
    "# that actually doesnt fix it we conditioned fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b113fb-4789-4672-ab30-87ee3cd3b59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9100f-6005-42ae-88f2-73cfea997836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27989e55-219d-422b-a0e8-4685c0076700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949978c-3adf-4b43-a58d-8c4a47c22f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af00b9-2d43-4e67-9e1a-f6dea7c96f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21437e1d-a54a-4ec4-a21a-78d89e87b14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc4486-3f62-43a5-a67e-e372849e9d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa792b-82cb-4d49-a87b-40c005e172df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb25235-b45d-4047-b4fa-44fcd6fd0069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3268440-16f6-492e-b03a-1ef1a24549e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b80d6e-852a-4f43-b59b-b1d8f8916b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64150bc9-be61-4658-9b3f-ef6905b2e802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867034b-df2b-4cba-b92f-31e6c3e39a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object and 'relevant_column' is the column to filter\n",
    "\n",
    "# # Step 1: Create masks for rows based on the condition\n",
    "# mask_less_equal = combined_adata.obs['kmeans'] < 2520\n",
    "# mask_greater = combined_adata.obs['kmeans'] >= 2520\n",
    "\n",
    "# # Filter the DataFrame based on these masks\n",
    "# filtered_obs_less_equal = combined_adata.obs[mask_less_equal]\n",
    "# filtered_obs_greater = combined_adata.obs[mask_greater]\n",
    "\n",
    "# # Step 2: Remove duplicate rows from those with values greater than 2520\n",
    "# unique_filtered_obs_greater = filtered_obs_greater.drop_duplicates()\n",
    "\n",
    "# # Combine the two filtered DataFrames\n",
    "# combined_filtered_obs = pd.concat([filtered_obs_less_equal, unique_filtered_obs_greater])\n",
    "\n",
    "# # Step 3: Update `combined_adata` with the combined filtered DataFrame\n",
    "# combined_adata_no_dupe = combined_adata[combined_adata.obs.index.isin(combined_filtered_obs.index)]\n",
    "\n",
    "# # Print the number of remaining rows\n",
    "# print(f\"Number of remaining rows: {combined_adata_no_dupe.n_obs}\")\n",
    "# # 3872924 is (252*15308) + 15309 extra from the extra 252 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41949c8-b6c1-4e09-a60b-1c2a02f18d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object and 'kmeans' is the column to filter\n",
    "\n",
    "# # Step 1: Create masks for rows based on the condition\n",
    "# mask_less_equal = combined_adata.obs['kmeans'] < 2520\n",
    "# mask_greater = combined_adata.obs['kmeans'] >= 2520\n",
    "\n",
    "# # Filter the DataFrame based on these masks\n",
    "# filtered_obs_less_equal = combined_adata.obs[mask_less_equal]\n",
    "# filtered_obs_greater = combined_adata.obs[mask_greater]\n",
    "\n",
    "# # Step 2: Remove duplicate rows from those with values greater than 2520\n",
    "# # Consider dropping duplicates based on all columns\n",
    "# unique_filtered_obs_greater = filtered_obs_greater.drop_duplicates()\n",
    "\n",
    "# # Print the number of rows before and after dropping duplicates\n",
    "# print(f\"Number of rows before dropping duplicates: {filtered_obs_greater.shape[0]}\")\n",
    "# print(f\"Number of rows after dropping duplicates: {unique_filtered_obs_greater.shape[0]}\")\n",
    "\n",
    "# # Combine the two filtered DataFrames\n",
    "# combined_filtered_obs = pd.concat([filtered_obs_less_equal, unique_filtered_obs_greater])\n",
    "\n",
    "# # Step 3: Update `combined_adata` with the combined filtered DataFrame\n",
    "# combined_adata_no_dupe = combined_adata[combined_adata.obs.index.isin(combined_filtered_obs.index)]\n",
    "\n",
    "# # Print the number of remaining rows\n",
    "# print(f\"Number of remaining rows: {combined_adata_no_dupe.n_obs}\")\n",
    "\n",
    "# # Additional check: Print the counts of 'kmeans' values before and after filtering\n",
    "# print(\"Counts before filtering:\")\n",
    "# print(combined_adata.obs['kmeans'].value_counts())\n",
    "\n",
    "# print(\"Counts after filtering:\")\n",
    "# print(combined_adata_no_dupe.obs['kmeans'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0c62c-27cd-49b5-a339-5a9a3823ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object and 'kmeans' is the column to filter\n",
    "\n",
    "# # Step 1: Create masks for rows based on the condition\n",
    "# filtered_less = combined_adata[combined_adata.obs['kmeans'] < 2520]\n",
    "# greater_equal = combined_adata[combined_adata.obs['kmeans'] >= 2520]\n",
    "\n",
    "# # # Filter the DataFrame based on these masks\n",
    "# # filtered_obs_less_equal = combined_adata.obs[mask_less_equal]\n",
    "# # filtered_obs_greater = combined_adata.obs[mask_greater]\n",
    "# print(\"C1\")\n",
    "\n",
    "# # Step 2: Remove duplicate rows from those with values greater than 2520\n",
    "# filtered_greater = greater_equal[~greater_equal.obs.duplicated(keep='first')]\n",
    "# #filtered_greater.X\n",
    "# filtered_less.X.shape[0]\n",
    "# #combined_adata_no_dupe = ad.concat([filtered_less, filtered_greater], join='outer')\n",
    "# # print(\"C2\")\n",
    "# # # Create a boolean mask to select rows from `combined_adata` that are either:\n",
    "# # # - Less than 2520 (no duplicates) \n",
    "# # # - Greater than or equal to 2520 and are unique\n",
    "# # # mask_final = np.concatenate([\n",
    "# # #     mask_less_equal.values,  # All rows where 'kmeans' < 2520\n",
    "# # #     np.isin(combined_adata.obs.index, unique_filtered_obs_greater.index)  # Unique rows where 'kmeans' >= 2520\n",
    "# # # ])\n",
    "# # mask_final = m\n",
    "# # print(\"C3\")\n",
    "# # # Step 3: Filter the AnnData object based on the combined mask\n",
    "# # combined_adata_no_dupe = combined_adata[mask_final]\n",
    "\n",
    "# # # Print the number of remaining rows\n",
    "# # print(f\"Number of remaining rows: {combined_adata_no_dupe.n_obs}\")\n",
    "# # print(\"C4\")\n",
    "# # # Additional check: Print the counts of 'kmeans' values before and after filtering\n",
    "# # print(\"Counts before filtering:\")\n",
    "# # print(combined_adata.obs['kmeans'].value_counts())\n",
    "\n",
    "# # print(\"Counts after filtering:\")\n",
    "# # print(combined_adata_no_dupe.obs['kmeans'].value_counts())\n",
    "# # print(\"C5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3533c7-ca41-411b-bbac-ae6076324efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `filtered_less` is the DataFrame or AnnData object you want to analyze\n",
    "\n",
    "# # Create bins with ranges of 10\n",
    "# bins = range(0, filtered_less.obs['kmeans'].max() + 10, 10)\n",
    "\n",
    "# # Create labels for each bin\n",
    "# bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# # Use pd.cut to categorize 'kmeans' values into bins\n",
    "# binned_kmeans = pd.cut(filtered_less.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# # Count occurrences in each bin\n",
    "# binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# # Check if any bin does not have exactly 15,308 counts\n",
    "# target_count = 15308\n",
    "# bins_with_different_count = binned_counts[binned_counts != target_count]\n",
    "\n",
    "# # Print bins that do not have exactly 15,308 counts\n",
    "# print(f\"Total number of bins: {len(binned_counts)}\")\n",
    "# if not bins_with_different_count.empty:\n",
    "#     print(\"Bins with counts different from 15,308:\")\n",
    "#     print(bins_with_different_count)\n",
    "# else:\n",
    "#     print(\"All bins have exactly 15,308 counts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11ecdb-a15c-4904-b0f1-d20e1053855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `filtered_less` is the DataFrame or AnnData object you want to analyze\n",
    "\n",
    "# # Create bins with ranges of 10\n",
    "# bins = range(0, filtered_less.obs['kmeans'].max() + 10, 10)\n",
    "\n",
    "# # Create labels for each bin\n",
    "# bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# # Use pd.cut to categorize 'kmeans' values into bins\n",
    "# binned_kmeans = pd.cut(filtered_less.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# # Count occurrences in each bin\n",
    "# binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# # Print the count in each bin\n",
    "# print(\"Counts in each bin:\")\n",
    "# print(binned_counts)\n",
    "\n",
    "# # Check if any bin does not have exactly 15,308 counts\n",
    "# target_count = 15308\n",
    "# bins_with_different_count = binned_counts[binned_counts != target_count]\n",
    "\n",
    "# # Print bins that do not have exactly 15,308 counts\n",
    "# print(f\"Total number of bins: {len(binned_counts)}\")\n",
    "# if not bins_with_different_count.empty:\n",
    "#     print(\"Bins with counts different from 15,308:\")\n",
    "#     print(bins_with_different_count)\n",
    "# else:\n",
    "#     print(\"All bins have exactly 15,308 counts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0560d-1cde-45b0-89d3-70b2cb4cef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object and 'kmeans' is the column to filter\n",
    "\n",
    "# # Step 1: Create masks for rows based on the condition\n",
    "# mask_less_equal = combined_adata.obs['kmeans'] < 2520\n",
    "# mask_greater = combined_adata.obs['kmeans'] >= 2520\n",
    "\n",
    "# # Filter the DataFrame based on these masks\n",
    "# filtered_obs_greater = combined_adata.obs[mask_greater]\n",
    "\n",
    "# # Step 2: Remove duplicate rows from those with values greater than 2520\n",
    "# unique_filtered_obs_greater = filtered_obs_greater.drop_duplicates()\n",
    "\n",
    "# # Convert the index of unique_filtered_obs_greater to a boolean mask\n",
    "# unique_mask = combined_adata.obs.index.isin(unique_filtered_obs_greater.index)\n",
    "\n",
    "# # Combine the masks for filtering\n",
    "# final_mask = mask_less_equal | unique_mask\n",
    "\n",
    "# # Step 3: Filter the AnnData object based on the combined mask\n",
    "# combined_adata_no_dupe = combined_adata[final_mask]\n",
    "\n",
    "# # Print the number of remaining rows\n",
    "# print(f\"Number of remaining rows: {combined_adata_no_dupe.n_obs}\")\n",
    "\n",
    "# # Additional check: Print the counts of 'kmeans' values before and after filtering\n",
    "# print(\"Counts before filtering:\")\n",
    "# print(combined_adata.obs['kmeans'].value_counts())\n",
    "\n",
    "# print(\"Counts after filtering:\")\n",
    "# print(combined_adata_no_dupe.obs['kmeans'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11333e87-a8c3-4c8c-8567-4bcbcfbd0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# # Create bins with ranges of 10\n",
    "# bins = range(0, combined_adata_no_dupe.obs['kmeans'].max() + 10, 10)\n",
    "\n",
    "# # Create labels for each bin\n",
    "# bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# # Use pd.cut to categorize 'kmeans' values into bins\n",
    "# binned_kmeans = pd.cut(combined_adata_no_dupe.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# # Count occurrences in each bin\n",
    "# binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# # Print the counts for each bin\n",
    "# print(binned_counts)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# # Create bins with ranges of 10\n",
    "# bins = range(0, combined_adata_no_dupe.obs['kmeans'].max() + 10, 10)\n",
    "\n",
    "# # Create labels for each bin\n",
    "# bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# # Use pd.cut to categorize 'kmeans' values into bins\n",
    "# binned_kmeans = pd.cut(combined_adata_no_dupe.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# # Count occurrences in each bin\n",
    "# binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# # Check if any bin does not have exactly 15,308 counts\n",
    "# target_count = 15308\n",
    "# bins_with_different_count = binned_counts[binned_counts != target_count]\n",
    "\n",
    "# # Print bins that do not have exactly 15,308 counts\n",
    "# if not bins_with_different_count.empty:\n",
    "#     print(\"Bins with counts different from 15,308:\")\n",
    "#     print(bins_with_different_count)\n",
    "# else:\n",
    "#     print(\"All bins have exactly 15,308 counts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd11ea-113b-427a-8a3d-68e3e48bdf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# # # Get the unique values and their counts in the 'kmeans' column\n",
    "# # kmeans_counts = combined_adata.obs['kmeans'].value_counts()\n",
    "\n",
    "# # # Print the unique values and their counts\n",
    "# # print(kmeans_counts)\n",
    "# # # Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# # # Calculate the average value in the 'kmeans' column\n",
    "# # average_kmeans = combined_adata.obs['kmeans'].mean()\n",
    "\n",
    "# # # Print the average value\n",
    "# # print(f\"Average value of 'kmeans': {average_kmeans}\")\n",
    "# # Assuming `combined_adata` is your AnnData object\n",
    "\n",
    "# # Filter for 'kmeans' values between 2520 and 2529\n",
    "# kmeans_range = combined_adata_.obs['kmeans'][(combined_adata.obs['kmeans'] >= 2520) & (combined_adata.obs['kmeans'] <= 2529)]\n",
    "\n",
    "# # Get the count of each 'kmeans' value within the range\n",
    "# kmeans_counts = kmeans_range.value_counts().sort_index()\n",
    "\n",
    "# # Print the counts for each 'kmeans' value in the range 2520 to 2529\n",
    "# print(kmeans_counts)\n",
    "# # sum to 30616 so that's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0624cc-c35d-41ed-aea9-70b8f7585d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # writing into turbo\n",
    "# combined_adata = combined_adata[combined_adata.obs['type'] == 'reprogrammed']\n",
    "# combined_adata.obs.sample(10)\n",
    "# combined_adata.write('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/perturbed_combined.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb80d2-67c9-4c59-b268-eb8d5f4bb569",
   "metadata": {},
   "source": [
    "# I'm just going to pretend like this isn't an issue for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0598a5b8-ca14-44ce-96dc-8c52058395f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_adata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_adata\u001b[49m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_adata' is not defined"
     ]
    }
   ],
   "source": [
    "combined_adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b888234-0531-416e-a0b3-5ee605df1c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_adata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming combined_adata is your AnnData object and 'kmeans' is the column to analyze\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get the minimum and maximum values\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m min_value \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_adata\u001b[49m\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m      8\u001b[0m max_value \u001b[38;5;241m=\u001b[39m combined_adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Define the bin edges with a width of 10\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_adata' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming combined_adata is your AnnData object and 'kmeans' is the column to analyze\n",
    "\n",
    "# Get the minimum and maximum values\n",
    "min_value = combined_adata.obs['kmeans'].min()\n",
    "max_value = combined_adata.obs['kmeans'].max()\n",
    "\n",
    "# Define the bin edges with a width of 10\n",
    "bins = np.arange(min_value, max_value + 10, 10)\n",
    "\n",
    "# Define bin labels\n",
    "bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# Categorize 'kmeans' values into bins\n",
    "binned_kmeans = pd.cut(combined_adata.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# Count occurrences in each bin\n",
    "binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# Prepare the results as an array of intervals and their counts\n",
    "intervals_counts = np.array(list(zip(binned_counts.index, binned_counts.values)))\n",
    "\n",
    "# Print the intervals and counts\n",
    "print(\"Intervals and their counts:\")\n",
    "print(intervals_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907586c-f2da-4ada-ac43-14eabec1f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming combined_adata is your AnnData object and 'kmeans' is the column to analyze\n",
    "\n",
    "# Get the minimum and maximum values\n",
    "min_value = combined_adata.obs['kmeans'].min()\n",
    "max_value = combined_adata.obs['kmeans'].max()\n",
    "\n",
    "# Define the bin edges with a width of 10\n",
    "bins = np.arange(min_value, max_value + 10, 10)\n",
    "\n",
    "# Define bin labels\n",
    "bin_labels = [f\"{i}-{i+9}\" for i in bins[:-1]]\n",
    "\n",
    "# Categorize 'kmeans' values into bins\n",
    "binned_kmeans = pd.cut(combined_adata.obs['kmeans'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "# Count occurrences in each bin\n",
    "binned_counts = binned_kmeans.value_counts().sort_index()\n",
    "\n",
    "# Prepare the results as an array of intervals and their counts\n",
    "intervals_counts = np.array(list(zip(binned_counts.index, binned_counts.values)))\n",
    "\n",
    "# Calculate the sum of the second column (counts)\n",
    "sum_of_counts = intervals_counts[:, 1].astype(int).sum()\n",
    "\n",
    "# Print the sum of the counts\n",
    "print(f\"Sum of counts in all bins: {sum_of_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede53ee5-cf84-45a2-96e9-1ebf72c1b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating out into problem part and not problem part:\n",
    "import pandas as pd\n",
    "\n",
    "# Define the bin label for the high bin\n",
    "high_bin_label = '2520-2529'\n",
    "\n",
    "# Create a mask for rows in the '2520-2529' bin\n",
    "high_bin_mask = binned_kmeans == high_bin_label\n",
    "\n",
    "# Create the high and low DataFrames based on the mask\n",
    "condensed_adata_high = combined_adata[high_bin_mask]\n",
    "condensed_adata_low = combined_adata[~high_bin_mask]\n",
    "\n",
    "# Print the number of rows in each DataFrame to verify\n",
    "print(f\"Number of rows in condensed_adata_high: {condensed_adata_high.n_obs}\")\n",
    "print(f\"Number of rows in condensed_adata_low: {condensed_adata_low.n_obs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1c4df-ec74-4432-a2a9-bc4f2f6d6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata\n",
    "\n",
    "def remove_duplicate_obs(adata):\n",
    "    # Identify duplicate indices\n",
    "    duplicated_indices = adata.obs.index.duplicated(keep='first')\n",
    "    \n",
    "    # Remove duplicate observations\n",
    "    adata = adata[~duplicated_indices].copy()\n",
    "    \n",
    "    return adata\n",
    "\n",
    "condensed_adata_high = remove_duplicate_obs(condensed_adata_high)\n",
    "#condensed_adata_high.n_obs\n",
    "condensed_adata_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ed821-94b7-482f-b9ef-b62569d97eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata_no_dupe_true = ad.concat([condensed_adata_low, condensed_adata_high])\n",
    "combined_adata_no_dupe_true.obs['kmeans'] -= 10\n",
    "combined_adata_no_dupe_true.obs.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb186506-7222-429a-9575-57a7614903a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be136709-722c-47a0-a5b2-38860c8003f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what you see above is what's in the file.\n",
    "combined_adata_no_dupe_true.write('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/perturbed_combined_good.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2b3fd-687a-4c57-bd6e-cb16869a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata_no_dupe_true = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/perturbed_combined_good.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4815de1-7998-44bb-b1fb-1605e6525c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata_no_dupe_true.obs.shape\n",
    "# this is the right shape!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409fbd1-3bf3-4982-a955-24b0b6493727",
   "metadata": {},
   "source": [
    "# New approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a0f9d-4325-424b-a4e8-da24cc77f331",
   "metadata": {},
   "source": [
    "#### Loading this all in is too hard. let's just take clusters directly from the files we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc124b-406f-4c0c-9036-19568f18b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'/nfs/turbo/umms-indikar/shared/projects/geneformer/8_14_originals_working/fib15k/2024-07-31_05-34-28_job_number_61.h5ad'\n",
    "#cluster 7 when 0-9\n",
    "# pick some rando hsc cells idrc/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3157dee5-04f4-4f89-987b-47af8a62c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliven/miniconda3/envs/geneformer2/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/oliven/miniconda3/envs/geneformer2/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/oliven/miniconda3/envs/geneformer2/lib/python3.10/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "#initial_adata is the fibroblasts\n",
    "hsc_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/originals/hsc_1_use_this_copy.h5ad')\n",
    "max_min_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-34-28_job_number_61.h5ad')\n",
    "max_min_adata = max_min_adata[max_min_adata.obs['type'] == 'reprogrammed']\n",
    "mean_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-34-03_job_number_77.h5ad')\n",
    "mean_adata = mean_adata[mean_adata.obs['type'] == 'reprogrammed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba08fe2-dd15-4ff8-bc47-6569adbeaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9425418-6506-4bdf-8235-68196bb49dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_300948/703621888.py:4: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  max_min_adata.obs['kmeans_clusters'] = kmeans.fit_predict(max_min_adata.X)\n",
      "/tmp/ipykernel_300948/703621888.py:6: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  mean_adata.obs['kmeans_clusters'] = kmeans.fit_predict(mean_adata.X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>length</th>\n",
       "      <th>ignore</th>\n",
       "      <th>standardized_cell_type</th>\n",
       "      <th>broad_type</th>\n",
       "      <th>__index_level_0__</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>recipe</th>\n",
       "      <th>type</th>\n",
       "      <th>kmeans_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15308</th>\n",
       "      <td>[14409, 12698, 10804, 15641, 1532, 16345, 9009...</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>TS_Vasculature</td>\n",
       "      <td>2048</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>109770</td>\n",
       "      <td>cell_1</td>\n",
       "      <td>GATA2;FOS;REL;IKZF1;MEF2C</td>\n",
       "      <td>reprogrammed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15309</th>\n",
       "      <td>[14409, 12698, 10804, 15641, 1532, 12119, 9190...</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>TS_Vasculature</td>\n",
       "      <td>2048</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>109771</td>\n",
       "      <td>cell_2</td>\n",
       "      <td>GATA2;FOS;REL;IKZF1;MEF2C</td>\n",
       "      <td>reprogrammed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15310</th>\n",
       "      <td>[14409, 12698, 10804, 15641, 1532, 3878, 9009,...</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>TS_Vasculature</td>\n",
       "      <td>2048</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>109774</td>\n",
       "      <td>cell_3</td>\n",
       "      <td>GATA2;FOS;REL;IKZF1;MEF2C</td>\n",
       "      <td>reprogrammed</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15311</th>\n",
       "      <td>[14409, 12698, 10804, 15641, 1532, 3878, 16916...</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>TS_Vasculature</td>\n",
       "      <td>2048</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>109776</td>\n",
       "      <td>cell_4</td>\n",
       "      <td>GATA2;FOS;REL;IKZF1;MEF2C</td>\n",
       "      <td>reprogrammed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15312</th>\n",
       "      <td>[14409, 12698, 10804, 15641, 1532, 6196, 16916...</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>TS_Vasculature</td>\n",
       "      <td>2048</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>109777</td>\n",
       "      <td>cell_5</td>\n",
       "      <td>GATA2;FOS;REL;IKZF1;MEF2C</td>\n",
       "      <td>reprogrammed</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_ids   cell_type  \\\n",
       "15308  [14409, 12698, 10804, 15641, 1532, 16345, 9009...  fibroblast   \n",
       "15309  [14409, 12698, 10804, 15641, 1532, 12119, 9190...  fibroblast   \n",
       "15310  [14409, 12698, 10804, 15641, 1532, 3878, 9009,...  fibroblast   \n",
       "15311  [14409, 12698, 10804, 15641, 1532, 3878, 16916...  fibroblast   \n",
       "15312  [14409, 12698, 10804, 15641, 1532, 6196, 16916...  fibroblast   \n",
       "\n",
       "              dataset length      ignore standardized_cell_type  broad_type  \\\n",
       "15308  TS_Vasculature   2048  fibroblast             Fibroblast  fibroblast   \n",
       "15309  TS_Vasculature   2048  fibroblast             Fibroblast  fibroblast   \n",
       "15310  TS_Vasculature   2048  fibroblast             Fibroblast  fibroblast   \n",
       "15311  TS_Vasculature   2048  fibroblast             Fibroblast  fibroblast   \n",
       "15312  TS_Vasculature   2048  fibroblast             Fibroblast  fibroblast   \n",
       "\n",
       "      __index_level_0__ cell_id                     recipe          type  \\\n",
       "15308            109770  cell_1  GATA2;FOS;REL;IKZF1;MEF2C  reprogrammed   \n",
       "15309            109771  cell_2  GATA2;FOS;REL;IKZF1;MEF2C  reprogrammed   \n",
       "15310            109774  cell_3  GATA2;FOS;REL;IKZF1;MEF2C  reprogrammed   \n",
       "15311            109776  cell_4  GATA2;FOS;REL;IKZF1;MEF2C  reprogrammed   \n",
       "15312            109777  cell_5  GATA2;FOS;REL;IKZF1;MEF2C  reprogrammed   \n",
       "\n",
       "       kmeans_clusters  \n",
       "15308                4  \n",
       "15309                8  \n",
       "15310                8  \n",
       "15311                0  \n",
       "15312                9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0)\n",
    "max_min_adata.obs['kmeans_clusters'] = kmeans.fit_predict(max_min_adata.X)\n",
    "\n",
    "mean_adata.obs['kmeans_clusters'] = kmeans.fit_predict(mean_adata.X)\n",
    "\n",
    "mean_adata.obs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade43ed3-0d9f-4206-a901-c7adf151a8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "np.random.seed(23)\n",
    "\n",
    "\n",
    "plot_max_adata = max_min_adata[(max_min_adata.obs['kmeans_clusters'] == 6)] #this is not arbitrary\n",
    "plot_min_adata = max_min_adata[(max_min_adata.obs['kmeans_clusters'] == 8)]\n",
    "random_indices_max = np.random.choice(plot_max_adata.shape[0], 150, replace=False)\n",
    "random_indices_min = np.random.choice(plot_min_adata.shape[0], 150, replace=False) \n",
    "plot_max_adata = plot_max_adata[random_indices_max]\n",
    "plot_min_adata = plot_min_adata[random_indices_min]\n",
    "\n",
    "plot_mean_adata = mean_adata[mean_adata.obs['kmeans_clusters'] == 1] #this is arbitrary\n",
    "random_indices_mean = np.random.choice(plot_mean_adata.shape[0], 300, replace=False)\n",
    "plot_mean_adata = plot_mean_adata[random_indices_mean]\n",
    "\n",
    "plot_min_adata.obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa296f0-10ae-49fd-bec3-30031d538823",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "\n",
    "random_indices_fib = np.random.choice(initial_adata.shape[0], 300, replace=False)\n",
    "plot_fib_adata = initial_adata[random_indices_fib]\n",
    "plot_fib_adata.obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8f452-27df-46a2-88e8-3e79150a0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "\n",
    "random_indices_hsc = np.random.choice(hsc_adata.shape[0], 300, replace=False)\n",
    "plot_hsc_adata = hsc_adata[random_indices_hsc]\n",
    "plot_hsc_adata.obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22d84f-1c23-4488-b812-112c18736b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a746c4-38c1-46c0-aba1-3a90c64df234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #clearing out obs\n",
    "\n",
    "plot_max_adata.obs = pd.DataFrame(index=plot_max_adata.obs.index)\n",
    "plot_min_adata.obs = pd.DataFrame(index=plot_min_adata.obs.index)\n",
    "\n",
    "plot_max_adata.obs['dataset'] = \"max_61_7\"\n",
    "plot_min_adata.obs['dataset'] = \"min_61_9\"\n",
    "\n",
    "plot_mean_adata.obs = pd.DataFrame(index=plot_mean_adata.obs.index)\n",
    "plot_mean_adata.obs['dataset'] = \"mean_77_2\"\n",
    "\n",
    "plot_hsc_adata.obs = pd.DataFrame(index=plot_hsc_adata.obs.index)\n",
    "plot_hsc_adata.obs['dataset'] = \"hsc_hsc1_NaN\"\n",
    "\n",
    "plot_fib_adata.obs = pd.DataFrame(index=plot_fib_adata.obs.index)\n",
    "plot_fib_adata.obs['dataset'] = \"fib_NaN_NaN\"\n",
    "\n",
    "plot_adata = ad.concat([plot_max_adata, plot_min_adata, plot_mean_adata, plot_fib_adata, plot_hsc_adata])\n",
    "plot_adata.obs.sample(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085a2d4-e1b7-404b-95c1-f9bfe124282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the UMAP reducer\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "umap_embedding = reducer.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a new DataFrame for easy plotting\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset'].values\n",
    "\n",
    "# Define custom colors with valid color names or hex codes\n",
    "colors = {\n",
    "    'max_61_7': '#301934',    # Dark purple\n",
    "    'min_61_9': '#FF00FF',     # Magenta\n",
    "    'mean_77_2': '#E6E6FA',   # Lavender\n",
    "    'hsc_hsc1_NaN': '#FF007F', # Bright pink\n",
    "    'fib_NaN_NaN': '#0000FF'   # Blue\n",
    "}\n",
    "\n",
    "# Map the colors to the dataset column\n",
    "umap_df['color'] = umap_df['dataset'].map(colors)\n",
    "\n",
    "# Plot the UMAP\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='dataset',\n",
    "    palette=colors,\n",
    "    s=20,  # Size of points\n",
    "    alpha=0.8  # Transparency for better visibility of overlapping points\n",
    ")\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('UMAP of plot_adata Vectors')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9bea2-4ff5-46b8-b722-e3be5eaf3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "datasets = ['max_61_7', 'min_61_9', 'mean_77_2', 'fib_NaN_NaN', 'hsc_hsc1_NaN']\n",
    "centroids_high_dim = {dataset: calculate_centroids(plot_adata, dataset) for dataset in datasets}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette='RdBu', alpha=0.6)\n",
    "\n",
    "# Add centroid markers\n",
    "centroid_labels = datasets\n",
    "for i, dataset in enumerate(datasets):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], marker='X', s=100, label=f'Centroid {dataset}', edgecolor='black', color='red')\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(datasets):\n",
    "    for j, end in enumerate(datasets):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], [centroids_umap[i, 1], centroids_umap[j, 1]], 'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12ef6d-f87a-4fc8-9fdb-a4306d99ee2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette='RdBu', alpha=0.6)\n",
    "\n",
    "# Add centroid markers for the combined dataset and others\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], marker='X', s=100, label=f'Centroid {dataset}', edgecolor='black', color='red')\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(centroid_labels):\n",
    "    for j, end in enumerate(centroid_labels):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], [centroids_umap[i, 1], centroids_umap[j, 1]], 'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df7454-b805-405e-bd75-42c9752acd1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each centroid\n",
    "centroid_colors = {\n",
    "    'max_min_combined': 'green',\n",
    "    'mean_77_2': '#B2182B',  # color from RdBu palette\n",
    "    'fib_NaN_NaN': '#2166AC',  # color from RdBu palette\n",
    "    'hsc_hsc1_NaN': '#F4A582'  # color from RdBu palette\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette='RdBu', alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=100, label=f'Centroid {dataset}', \n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(centroid_labels):\n",
    "    for j, end in enumerate(centroid_labels):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], \n",
    "                     [centroids_umap[i, 1], centroids_umap[j, 1]], \n",
    "                     'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, \n",
    "                         (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', \n",
    "                     color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dccbab-9a1f-435a-8a71-6043a97a72c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': 'blue',  # Example color\n",
    "    'min_61_9': 'orange',  # Example color\n",
    "    'mean_77_2': '#E41A1C',\n",
    "    'fib_NaN_NaN': '#377EB8',\n",
    "    'hsc_hsc1_NaN': '#FF7F00',\n",
    "    'max_min_combined': 'green'\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=100, label=f'Centroid {dataset}', \n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(centroid_labels):\n",
    "    for j, end in enumerate(centroid_labels):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], \n",
    "                     [centroids_umap[i, 1], centroids_umap[j, 1]], \n",
    "                     'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, \n",
    "                         (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', \n",
    "                     color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2db644-e31a-4e1d-accb-ecd0d71ba0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7dccf8-26af-4489-b374-771c4a4f7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap between mean_61_7 and hsc_hsc1_NaN datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5602b7-c576-4953-b4f9-dc850f637d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Extract the relevant data points\n",
    "mean_data = plot_adata[plot_adata.obs['dataset'] == 'mean_77_2'].X\n",
    "hsc_data = plot_adata[plot_adata.obs['dataset'] == 'hsc_hsc1_NaN'].X\n",
    "\n",
    "# Compute pairwise distances between the datasets\n",
    "pairwise_distances = cdist(mean_data, hsc_data, metric='euclidean')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pairwise_distances, cmap='viridis')\n",
    "plt.title('Pairwise Distances between mean_61_7 and hsc_hsc1_NaN Datasets')\n",
    "plt.xlabel('hsc_hsc1_NaN Points')\n",
    "plt.ylabel('mean_77_2 Points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d92b1b-3f36-4669-ab3a-b76bd41167af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "# List of datasets\n",
    "datasets = ['fib_NaN_NaN', 'hsc_hsc1_NaN', 'max_61_7', 'mean_77_2']\n",
    "\n",
    "# Initialize a list to hold data and labels\n",
    "data_matrices = []\n",
    "labels = []\n",
    "\n",
    "# Extract data points for each dataset and store them\n",
    "for dataset in datasets:\n",
    "    data = plot_adata[plot_adata.obs['dataset'] == dataset].X\n",
    "    data_matrices.append(data)\n",
    "    labels.extend([dataset] * data.shape[0])\n",
    "\n",
    "# Compute pairwise distances between all data points across datasets\n",
    "pairwise_distances = cdist(np.vstack(data_matrices), np.vstack(data_matrices), metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering to reorder datasets\n",
    "linked = linkage(pairwise_distances, method='average')\n",
    "order = leaves_list(linked)\n",
    "\n",
    "# Reorder the distance matrix and labels according to the clustering\n",
    "ordered_distances = pairwise_distances[order, :][:, order]\n",
    "ordered_labels = np.array(labels)[order]\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(ordered_distances, cmap='viridis', xticklabels=ordered_labels, yticklabels=ordered_labels)\n",
    "plt.title('Pairwise Distances between Datasets')\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Data Points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc5014-c576-4842-a998-35adb287b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "# List of datasets\n",
    "datasets = ['fib_NaN_NaN', 'hsc_hsc1_NaN', 'max_61_7', 'mean_77_2']\n",
    "\n",
    "# Initialize a list to hold data and labels\n",
    "data_matrices = []\n",
    "dataset_labels = []\n",
    "\n",
    "# Extract data points for each dataset and store them\n",
    "for dataset in datasets:\n",
    "    data = plot_adata[plot_adata.obs['dataset'] == dataset].X\n",
    "    data_matrices.append(data)\n",
    "    dataset_labels.extend([dataset] * data.shape[0])\n",
    "\n",
    "# Compute pairwise distances between all data points across datasets\n",
    "pairwise_distances = cdist(np.vstack(data_matrices), np.vstack(data_matrices), metric='euclidean')\n",
    "\n",
    "# Perform hierarchical clustering to reorder datasets\n",
    "linked = linkage(pairwise_distances, method='average')\n",
    "order = leaves_list(linked)\n",
    "\n",
    "# Reorder the distance matrix and dataset labels according to the clustering\n",
    "ordered_distances = pairwise_distances[order, :][:, order]\n",
    "ordered_dataset_labels = np.array(dataset_labels)[order]\n",
    "\n",
    "# Map minor labels to dataset names\n",
    "unique_datasets = np.unique(ordered_dataset_labels)\n",
    "axis_labels = []\n",
    "for label in ordered_dataset_labels:\n",
    "    for dataset in unique_datasets:\n",
    "        if label == dataset:\n",
    "            axis_labels.append(dataset)\n",
    "            break\n",
    "\n",
    "# Plot the heatmap without minor labels\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(ordered_distances, cmap='viridis', xticklabels=False, yticklabels=False)\n",
    "plt.title('Pairwise Distances between Datasets')\n",
    "\n",
    "# Set major ticks at the centers of each block of data points and label with dataset names\n",
    "num_points = [np.sum(ordered_dataset_labels == dataset) for dataset in unique_datasets]\n",
    "positions = np.cumsum([0] + num_points) - 0.5 * np.array(num_points)\n",
    "\n",
    "plt.xticks(positions, unique_datasets, rotation=45, ha='right')\n",
    "plt.yticks(positions, unique_datasets, rotation=0)\n",
    "\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5f8f5-2c73-4417-9dd9-65d1e3b3c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# List of datasets\n",
    "datasets = ['fib_NaN_NaN', 'hsc_hsc1_NaN', 'max_61_7', 'mean_77_2']\n",
    "\n",
    "# Initialize a list to hold data and labels\n",
    "data_matrices = []\n",
    "dataset_labels = []\n",
    "\n",
    "# Extract data points for each dataset and store them\n",
    "for dataset in datasets:\n",
    "    data = plot_adata[plot_adata.obs['dataset'] == dataset].X\n",
    "    data_matrices.append(data)\n",
    "    dataset_labels.extend([dataset] * data.shape[0])\n",
    "\n",
    "# Compute pairwise distances between all data points across datasets\n",
    "pairwise_distances = cdist(np.vstack(data_matrices), np.vstack(data_matrices), metric='euclidean')\n",
    "\n",
    "# Convert the full distance matrix to a condensed distance matrix\n",
    "condensed_distances = squareform(pairwise_distances)\n",
    "\n",
    "# Perform hierarchical clustering to reorder datasets\n",
    "linked = linkage(condensed_distances, method='average')\n",
    "order = leaves_list(linked)\n",
    "\n",
    "# Reorder the distance matrix and dataset labels according to the clustering\n",
    "ordered_distances = pairwise_distances[order, :][:, order]\n",
    "ordered_dataset_labels = np.array(dataset_labels)[order]\n",
    "\n",
    "# Compute the number of points per dataset\n",
    "unique_datasets, counts = np.unique(ordered_dataset_labels, return_counts=True)\n",
    "num_datasets = len(unique_datasets)\n",
    "positions = np.concatenate([[0], np.cumsum(counts)])\n",
    "\n",
    "# Define positions for the ticks based on dataset block positions\n",
    "tick_positions = positions[:-1] + np.diff(positions) / 2\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(ordered_distances, cmap='viridis', xticklabels=False, yticklabels=False)\n",
    "\n",
    "# Set major ticks and labels\n",
    "ax.set_xticks(tick_positions)\n",
    "ax.set_xticklabels(unique_datasets, rotation=45, ha='right')\n",
    "ax.set_yticks(tick_positions)\n",
    "ax.set_yticklabels(unique_datasets, rotation=0)\n",
    "\n",
    "plt.title('Pairwise Distances between Datasets')\n",
    "plt.xlabel('Dataset')\n",
    "plt.ylabel('Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b89052-d7ac-42d3-b4ad-41a8932b0c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f5615-9fdc-4b66-832e-4466dfe7f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebcc915d-3e60-4933-8a7e-9c053925a8c5",
   "metadata": {},
   "source": [
    "## Fine Tuning the Distance UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9054846-9b4b-4fe5-874b-00452351e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_adata is the fibroblasts\n",
    "hsc_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/originals/hsc_1_use_this_copy.h5ad')\n",
    "max_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_05-34-28_job_number_61.h5ad')\n",
    "max_adata = max_adata[max_adata.obs['type'] == 'reprogrammed']\n",
    "mean_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/8_14_originals_working/2024-07-31_06-34-03_job_number_77.h5ad')\n",
    "mean_adata = mean_adata[mean_adata.obs['type'] == 'reprogrammed']\n",
    "#cluster 9 of 61 seems to do the worst in recipe_diff and reprog_to_hsc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749cff5-0b0f-43ee-b40c-9e01c5bea75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "datasets = ['max_61_7', 'mean_77_2', 'fib_NaN_NaN', 'hsc_hsc1_NaN']\n",
    "centroids_high_dim = {dataset: calculate_centroids(plot_adata, dataset) for dataset in datasets}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette='RdBu', alpha=0.6)\n",
    "\n",
    "# Add centroid markers\n",
    "centroid_labels = datasets\n",
    "for i, dataset in enumerate(datasets):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], marker='X', s=100, label=f'Centroid {dataset}', edgecolor='black', color='red')\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(datasets):\n",
    "    for j, end in enumerate(datasets):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], [centroids_umap[i, 1], centroids_umap[j, 1]], 'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ff87d-f985-493f-a19f-e7de6d2e6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import anndata as ad\n",
    "\n",
    "# Load the HSC data\n",
    "hsc_adata = ad.read_h5ad('/nfs/turbo/umms-indikar/shared/projects/geneformer/fib15k/originals/hsc_1_use_this_copy.h5ad')\n",
    "\n",
    "# Initialize a list to store the centroids of each kmeans cluster\n",
    "kmeans_centroids = []\n",
    "\n",
    "# Calculate the centroid for each cluster\n",
    "for cluster in range(10):  # Assuming there are 10 clusters labeled from 0 to 9\n",
    "    cluster_data = max_min_adata[max_min_adata.obs['kmeans_clusters'] == cluster].X\n",
    "    centroid = np.mean(cluster_data, axis=0)\n",
    "    kmeans_centroids.append(centroid)\n",
    "\n",
    "# Calculate the centroid of the HSC data\n",
    "hsc_centroid = np.mean(hsc_adata.X, axis=0)\n",
    "\n",
    "# Compute pairwise cosine distances between each K-means centroid and the HSC centroid\n",
    "distances_to_hsc = cosine_distances(kmeans_centroids, hsc_centroid.reshape(1, -1))\n",
    "\n",
    "# Print the distances\n",
    "for i, distance in enumerate(distances_to_hsc):\n",
    "    print(f\"Distance from K-means cluster {i} to HSC centroid: {distance[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e09bb6-4220-4e1e-a3bb-1ebfcdb48487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22795b5-19a5-4168-be71-958a63725003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c85f9-4831-4bb6-a212-bf7eadd9bac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb23cc-c839-4c90-9e52-8a61bfc5c34d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490961b-d5ff-44f7-acc4-5f6626e3d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc65e8-1d54-4df4-8c7e-0ac26d2e0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': 'blue',  # Example color\n",
    "    'min_61_9': 'orange',  # Example color\n",
    "    'mean_77_2': '#E41A1C',\n",
    "    'fib_NaN_NaN': '#377EB8',\n",
    "    'hsc_hsc1_NaN': '#FF7F00',\n",
    "    'max_min_combined': 'green'\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array(list(centroids_high_dim.values()))\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=100, label=f'Centroid {dataset}', \n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# 4. Draw Lines Between Centroids and Compute Cosine Distances\n",
    "distances = cosine_distances(centroids_high_dim_matrix)\n",
    "for i, start in enumerate(centroid_labels):\n",
    "    for j, end in enumerate(centroid_labels):\n",
    "        if i < j:\n",
    "            plt.plot([centroids_umap[i, 0], centroids_umap[j, 0]], \n",
    "                     [centroids_umap[i, 1], centroids_umap[j, 1]], \n",
    "                     'k--', alpha=0.6)\n",
    "            mid_point = [(centroids_umap[i, 0] + centroids_umap[j, 0]) / 2, \n",
    "                         (centroids_umap[i, 1] + centroids_umap[j, 1]) / 2]\n",
    "            plt.text(mid_point[0], mid_point[1], f'{distances[i, j]:.2f}', \n",
    "                     color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91637f2a-5357-4f8c-bdcb-e1f9bd276578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': '#C93784',  # color 5\n",
    "    'min_61_9': '#0077CC',  # COLOR 1\n",
    "    'mean_77_2': '#A23A8E', # color 4\n",
    "    'fib_NaN_NaN': '#4C52A5', # COLOR 2\n",
    "    'hsc_hsc1_NaN': '#E34390', #color 6 - pinkest\n",
    "    'max_min_combined': '#7D3F98' # color 3\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array([centroid_combined, centroid_max, centroid_min, centroid_mean, centroid_fib, centroid_hsc])\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Calculate and Display Only the Distances to HSC Centroid\n",
    "# Get the index of the HSC centroid\n",
    "hsc_index = list(centroids_high_dim.keys()).index('hsc_hsc1_NaN')\n",
    "\n",
    "# Compute cosine distances from all other centroids to the HSC centroid\n",
    "distances_to_hsc = cosine_distances(centroids_high_dim_matrix, centroids_high_dim_matrix[hsc_index:hsc_index+1])\n",
    "\n",
    "# 4. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=100, label=f'Centroid {dataset}', \n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# Draw lines and display distances only between centroids and HSC centroid\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    if i != hsc_index:\n",
    "        plt.plot([centroids_umap[i, 0], centroids_umap[hsc_index, 0]], \n",
    "                 [centroids_umap[i, 1], centroids_umap[hsc_index, 1]], \n",
    "                 'k--', alpha=0.6)\n",
    "        mid_point = [(centroids_umap[i, 0] + centroids_umap[hsc_index, 0]) / 2, \n",
    "                     (centroids_umap[i, 1] + centroids_umap[hsc_index, 1]) / 2]\n",
    "        plt.text(mid_point[0], mid_point[1], f'{distances_to_hsc[i, 0]:.2f}', \n",
    "                 color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances to HSC Centroid')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f12bfd-7d64-4b3f-8524-bf01741799bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': '#C93784',  # color 5\n",
    "    'min_61_9': '#0077CC',  # COLOR 1\n",
    "    'mean_77_2': '#A23A8E', # color 4\n",
    "    'fib_NaN_NaN': '#4C52A5', # COLOR 2\n",
    "    'hsc_hsc1_NaN': '#E34390', #color 6 - pinkest\n",
    "    'max_min_combined': '#7D3F98' # color 3\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array([centroid_combined, centroid_max, centroid_min, centroid_mean, centroid_fib, centroid_hsc])\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Calculate and Display Only the Distances to HSC Centroid\n",
    "# Get the index of the HSC centroid\n",
    "hsc_index = list(centroids_high_dim.keys()).index('hsc_hsc1_NaN')\n",
    "\n",
    "# Compute cosine distances from all other centroids to the HSC centroid\n",
    "distances_to_hsc = cosine_distances(centroids_high_dim_matrix, centroids_high_dim_matrix[hsc_index:hsc_index+1])\n",
    "\n",
    "# 4. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=200, label=f'Centroid {dataset}',  # Increased marker size\n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# Draw lines and display distances only between centroids and HSC centroid\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    if i != hsc_index:\n",
    "        plt.plot([centroids_umap[i, 0], centroids_umap[hsc_index, 0]], \n",
    "                 [centroids_umap[i, 1], centroids_umap[hsc_index, 1]], \n",
    "                 'k--', alpha=0.6)\n",
    "        mid_point = [(centroids_umap[i, 0] + centroids_umap[hsc_index, 0]) / 2, \n",
    "                     (centroids_umap[i, 1] + centroids_umap[hsc_index, 1]) / 2]\n",
    "        plt.text(mid_point[0], mid_point[1], f'{distances_to_hsc[i, 0]:.2f}', \n",
    "                 color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances to HSC Centroid')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d129c-9251-404d-ad6d-3d4b6a2beed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': '#C93784',  # color 5\n",
    "    'min_61_9': '#0077CC',  # COLOR 1\n",
    "    'mean_77_2': '#A23A8E', # color 4\n",
    "    'fib_NaN_NaN': '#4C52A5', # COLOR 2\n",
    "    'hsc_hsc1_NaN': '#E34390', #color 6 - pinkest\n",
    "    'max_min_combined': '#7D3F98' # color 3\n",
    "}\n",
    "\n",
    "# Define a dictionary for renaming in the legend\n",
    "legend_labels = {\n",
    "    'max_61_7': 'Max 61 7',\n",
    "    'min_61_9': 'Min 61 9',\n",
    "    'mean_77_2': 'Mean 77 2',\n",
    "    'fib_NaN_NaN': 'Fib NaN NaN',\n",
    "    'hsc_hsc1_NaN': 'HSC HSC1 NaN',\n",
    "    'max_min_combined': 'Max & Min Combined'\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array([centroid_combined, centroid_max, centroid_min, centroid_mean, centroid_fib, centroid_hsc])\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Calculate and Display Only the Distances to HSC Centroid\n",
    "# Get the index of the HSC centroid\n",
    "hsc_index = list(centroids_high_dim.keys()).index('hsc_hsc1_NaN')\n",
    "\n",
    "# Compute cosine distances from all other centroids to the HSC centroid\n",
    "distances_to_hsc = cosine_distances(centroids_high_dim_matrix, centroids_high_dim_matrix[hsc_index:hsc_index+1])\n",
    "\n",
    "# 4. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=200, label=legend_labels[dataset],  # Increased marker size and renamed label\n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# Draw lines and display distances only between centroids and HSC centroid\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    if i != hsc_index:\n",
    "        plt.plot([centroids_umap[i, 0], centroids_umap[hsc_index, 0]], \n",
    "                 [centroids_umap[i, 1], centroids_umap[hsc_index, 1]], \n",
    "                 'k--', alpha=0.6)\n",
    "        mid_point = [(centroids_umap[i, 0] + centroids_umap[hsc_index, 0]) / 2, \n",
    "                     (centroids_umap[i, 1] + centroids_umap[hsc_index, 1]) / 2]\n",
    "        plt.text(mid_point[0], mid_point[1], f'{distances_to_hsc[i, 0]:.2f}', \n",
    "                 color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances to HSC Centroid')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09b582-edd9-46d6-8b2c-cc61393c16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIxing the overlap to read lines more easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304fe5c-291b-42fb-86da-257362f0de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import umap\n",
    "\n",
    "# Ensure no duplicate indices in plot_adata.obs\n",
    "plot_adata.obs = plot_adata.obs.reset_index(drop=True)\n",
    "\n",
    "# 1. Calculate Centroids in High-Dimensional Space\n",
    "def calculate_centroids(adata, dataset_name):\n",
    "    data = adata[adata.obs['dataset'] == dataset_name].X\n",
    "    return np.mean(data, axis=0)\n",
    "\n",
    "# Calculate centroids for individual datasets\n",
    "centroid_max = calculate_centroids(plot_adata, 'max_61_7')\n",
    "centroid_min = calculate_centroids(plot_adata, 'min_61_9')\n",
    "\n",
    "# Combine the centroids for max_61_7 and min_61_9\n",
    "centroid_combined = np.mean([centroid_max, centroid_min], axis=0)\n",
    "\n",
    "# Calculate centroids for other datasets\n",
    "centroid_mean = calculate_centroids(plot_adata, 'mean_77_2')\n",
    "centroid_fib = calculate_centroids(plot_adata, 'fib_NaN_NaN')\n",
    "centroid_hsc = calculate_centroids(plot_adata, 'hsc_hsc1_NaN')\n",
    "\n",
    "# Create a dictionary of centroids\n",
    "centroids_high_dim = {\n",
    "    'max_min_combined': centroid_combined,\n",
    "    'max_61_7': centroid_max,\n",
    "    'min_61_9': centroid_min,\n",
    "    'mean_77_2': centroid_mean,\n",
    "    'fib_NaN_NaN': centroid_fib,\n",
    "    'hsc_hsc1_NaN': centroid_hsc\n",
    "}\n",
    "\n",
    "# Define colors for each dataset\n",
    "centroid_colors = {\n",
    "    'max_61_7': '#C93784',  # color 5\n",
    "    'min_61_9': '#0077CC',  # COLOR 1\n",
    "    'mean_77_2': '#A23A8E', # color 4\n",
    "    'fib_NaN_NaN': '#4C52A5', # COLOR 2\n",
    "    'hsc_hsc1_NaN': '#E34390', #color 6 - pinkest\n",
    "    'max_min_combined': '#7D3F98' # color 3\n",
    "}\n",
    "\n",
    "# 2. Transform Centroids to UMAP Space\n",
    "# Fit UMAP on the entire dataset to get the same UMAP transformation\n",
    "umap_model = umap.UMAP()\n",
    "umap_embedding = umap_model.fit_transform(plot_adata.X)\n",
    "\n",
    "# Create a DataFrame for UMAP plot\n",
    "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['dataset'] = plot_adata.obs['dataset']\n",
    "\n",
    "# Project centroids to UMAP space\n",
    "centroids_high_dim_matrix = np.array([centroid_combined, centroid_max, centroid_min, centroid_mean, centroid_fib, centroid_hsc])\n",
    "centroids_umap = umap_model.transform(centroids_high_dim_matrix)\n",
    "\n",
    "# 3. Calculate and Display Only the Distances to HSC Centroid\n",
    "# Get the index of the HSC centroid\n",
    "hsc_index = list(centroids_high_dim.keys()).index('hsc_hsc1_NaN')\n",
    "\n",
    "# Compute cosine distances from all other centroids to the HSC centroid\n",
    "distances_to_hsc = cosine_distances(centroids_high_dim_matrix, centroids_high_dim_matrix[hsc_index:hsc_index+1])\n",
    "\n",
    "# 4. Plot the UMAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the UMAP scatter plot with the updated palette\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='dataset', palette=centroid_colors, alpha=0.6)\n",
    "\n",
    "# Add centroid markers with specific colors\n",
    "centroid_labels = list(centroids_high_dim.keys())\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    plt.scatter(centroids_umap[i, 0], centroids_umap[i, 1], \n",
    "                marker='X', s=200, label=f'Centroid {dataset}',  # Increased marker size\n",
    "                edgecolor='black', color=centroid_colors[dataset])\n",
    "\n",
    "# Draw lines and display distances only between centroids and HSC centroid\n",
    "for i, dataset in enumerate(centroid_labels):\n",
    "    if i != hsc_index:\n",
    "        plt.plot([centroids_umap[i, 0], centroids_umap[hsc_index, 0]], \n",
    "                 [centroids_umap[i, 1], centroids_umap[hsc_index, 1]], \n",
    "                 'k--', alpha=0.6)\n",
    "        mid_point = [(centroids_umap[i, 0] + centroids_umap[hsc_index, 0]) / 2, \n",
    "                     (centroids_umap[i, 1] + centroids_umap[hsc_index, 1]) / 2]\n",
    "        plt.text(mid_point[0], mid_point[1], f'{distances_to_hsc[i, 0]:.2f}', \n",
    "                 color='black', ha='center')\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('UMAP with Centroids and Cosine Distances to HSC Centroid')\n",
    "plt.xlabel('UMAP1')\n",
    "plt.ylabel('UMAP2')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a285a-a410-41ee-8b4c-08c705beb2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer2",
   "language": "python",
   "name": "geneformer2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
