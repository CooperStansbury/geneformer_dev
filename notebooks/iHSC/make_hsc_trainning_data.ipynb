{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a2b29a-c678-4874-a1bf-5af3a7d00ed9",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Classification of Cardiomyopathy Disease States\n",
    "Please note that, as usual with deep learning models, we **highly** recommend tuning learning hyperparameters for all fine-tuning applications as this can significantly improve model performance. Example below uses previously optimized hyperparameters, but one can optimize hyperparameters with the argument n_hyperopt_trials=n in cc.validate() where n>0 and represents the number of trials for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe3b79b-aa8f-416c-9755-7f9299d6a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORES=40\n",
      "GPUS=3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from geneformer import Classifier\n",
    "\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import load_dataset\n",
    "from geneformer import EmbExtractor\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(0, '../../scripts/')\n",
    "import geneformer_utils as gtu\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "CORES = os.cpu_count()\n",
    "GPUS = torch.cuda.device_count()\n",
    "print(f\"{CORES=}\")\n",
    "print(f\"{GPUS=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d15eaf9-f42b-4999-9f8c-7d70758fc2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset='weng_old1_BMMC_HSPC.dataset'\n",
      "dataset='weng_young2_all.dataset'\n",
      "dataset='pellin.dataset'\n",
      "dataset='weng_young1_all_t2.dataset'\n",
      "dataset='weng_young1_all_t1.dataset'\n",
      "dataset='TS_Vasculature.dataset'\n",
      "dataset='weng_old2_BMMC_HSPC.dataset'\n",
      "dataset='iHSC.dataset'\n",
      "dataset='TS_Fat.dataset'\n",
      "dataset='TS_Blood.dataset'\n",
      "dataset='TS_Bone_Marrow.dataset'\n",
      "dataset='weng_young2_HSC.dataset'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[625, 6396, 4279, 4193, 20799, 7658, 4474, 428...</td>\n",
       "      <td>B</td>\n",
       "      <td>weng_old1_BMMC_HSPC</td>\n",
       "      <td>1029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[202, 12792, 8708, 10265, 10905, 3651, 7725, 1...</td>\n",
       "      <td>MDP</td>\n",
       "      <td>weng_old1_BMMC_HSPC</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7725, 10265, 1329, 3187, 5561, 13513, 3356, 9...</td>\n",
       "      <td>GMP</td>\n",
       "      <td>weng_old1_BMMC_HSPC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14577, 17163, 10265, 7725, 18049, 6816, 806, ...</td>\n",
       "      <td>HSC</td>\n",
       "      <td>weng_old1_BMMC_HSPC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20799, 10265, 20499, 14698, 12621, 11159, 782...</td>\n",
       "      <td>nan</td>\n",
       "      <td>weng_old1_BMMC_HSPC</td>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids cell_type  \\\n",
       "0  [625, 6396, 4279, 4193, 20799, 7658, 4474, 428...         B   \n",
       "1  [202, 12792, 8708, 10265, 10905, 3651, 7725, 1...       MDP   \n",
       "2  [7725, 10265, 1329, 3187, 5561, 13513, 3356, 9...       GMP   \n",
       "3  [14577, 17163, 10265, 7725, 18049, 6816, 806, ...       HSC   \n",
       "4  [20799, 10265, 20499, 14698, 12621, 11159, 782...       nan   \n",
       "\n",
       "               dataset  length  \n",
       "0  weng_old1_BMMC_HSPC    1029  \n",
       "1  weng_old1_BMMC_HSPC    1850  \n",
       "2  weng_old1_BMMC_HSPC    2048  \n",
       "3  weng_old1_BMMC_HSPC    2048  \n",
       "4  weng_old1_BMMC_HSPC    2048  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpath = \"/scratch/indikar_root/indikar1/shared_data/geneformer/datasets/\"\n",
    "\n",
    "\n",
    "def load_data(path, sample_size=None):\n",
    "    \"\"\"\n",
    "    Loads data from a file, processes cell types, and returns a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the dataset file.\n",
    "        sample_size (int, optional): Number of cells to sample. Defaults to None.\n",
    "    Returns:\n",
    "        pandas.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    df = gtu.load_data_as_dataframe(path, num_cells=sample_size, shuffle=True)\n",
    "\n",
    "    if \"iHSC\" in path:\n",
    "        df['cell_type'] = \"iHSC\"\n",
    "    elif \"pellin\" in path:\n",
    "        df['cell_type'] = df['dataset']\n",
    "    elif \"weng\" in path:\n",
    "        df['cell_type'] = df['STD.CellType']\n",
    "    else:\n",
    "        df['cell_type'] = df['free_annotation']\n",
    "\n",
    "    # Extract basename without extension and assign to 'dataset' column\n",
    "    df['dataset'] = os.path.splitext(os.path.basename(path))[0]\n",
    "    df = df[['input_ids', 'cell_type', 'dataset', 'length']]\n",
    "\n",
    "    return df\n",
    "\n",
    "sample_size = None\n",
    "\n",
    "df = []\n",
    "\n",
    "for dataset in os.listdir(dpath):\n",
    "    print(f\"{dataset=}\")\n",
    "    data_path = f\"{dpath}{dataset}\"\n",
    "    tmp = load_data(data_path, sample_size)\n",
    "    \n",
    "    df.append(tmp)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738ab8b-4737-422c-a32f-995b1cea63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42012c31-26b8-40bc-ab57-f04f7cfc62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fbc26c-b2cb-4483-a209-285b3835b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = \"../ihsc_cell_types.csv\"\n",
    "# cell_map = pd.read_csv(fpath, comment=\"#\")\n",
    "\n",
    "# df = pd.merge(df, \n",
    "#               cell_map,\n",
    "#               how='left',\n",
    "#               left_on='cell_type',\n",
    "#               right_on='label',\n",
    "# )\n",
    "\n",
    "# df = df.rename(columns={'label' : 'ignore'})\n",
    "\n",
    "# df = df[df['standardized_cell_type'].notna()]\n",
    "# print(f\"{df.shape=}\")\n",
    "# print()\n",
    "# print(df['standardized_cell_type'].value_counts())\n",
    "# print()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46e4cc-9bbf-41d0-9039-3dc76d7c99cd",
   "metadata": {},
   "source": [
    "# save the data to disk to make it easier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2b9d87-00c4-4708-b8c2-5d904b7f5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_output_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "\n",
    "# data = Dataset.from_pandas(df)\n",
    "# data.save_to_disk(data_output_path)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a887a-36d7-433c-9074-46322bcaf023",
   "metadata": {},
   "source": [
    "# Set up the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3d8a2f-0e77-4524-a029-bb34ed1b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"num_train_epochs\" : 3,\n",
    "    \"lr_scheduler_type\" : \"polynomial\",\n",
    "    \"per_device_train_batch_size\" : 20,\n",
    "    \"seed\" : 73,\n",
    "    \"learning_rate\" : 0.000804,\n",
    "    \"warmup_steps\" : 1812,\n",
    "    \"weight_decay\" : 0.258828,\n",
    "}\n",
    "\n",
    "cell_state_dict = {\n",
    "    \"state_key\" : \"standardized_cell_type\", \n",
    "    \"states\" : \"all\",\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sample_size = None\n",
    "\n",
    "cc = Classifier(classifier = \"cell\",\n",
    "                cell_state_dict = cell_state_dict,\n",
    "                training_args = training_args,\n",
    "                max_ncells = sample_size,\n",
    "                freeze_layers = 2,\n",
    "                num_crossval_splits = 1,\n",
    "                forward_batch_size = 200,\n",
    "                nproc = CORES,\n",
    "                ngpu = GPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1f146-e8e9-4160-8b60-239a3e3c7037",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d10d0a-dba4-4d66-a3d7-abbac2a0ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_output_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "# output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "# output_prefix = \"prepared_hsc\"\n",
    "\n",
    "# cc.prepare_data(input_data_file=data_output_path,\n",
    "#                 output_directory=output_dir,\n",
    "#                 output_prefix=output_prefix,\n",
    "#                 test_size=0.3)\n",
    "\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20bd09c4-5231-43f0-aedd-493e72fa5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "939d01ad-303e-4291-94ec-6a5b34437087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# with profile(\n",
    "#     activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "#     record_shapes=True,\n",
    "#     profile_memory=True,  \n",
    "#     with_stack=True  \n",
    "# ) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         # Your training loop code here \n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))  # View top 10 GPU operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a849397a-1727-497f-87bb-e56908cc2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240711_geneformer_cellClassifier_prepared_hsc/â€™: File exists\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240711_geneformer_cellClassifier_prepared_hsc/ksplit1â€™: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation split: 1/1 ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6681' max='6681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6681/6681 3:27:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.312397</td>\n",
       "      <td>0.891377</td>\n",
       "      <td>0.804018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.220915</td>\n",
       "      <td>0.921796</td>\n",
       "      <td>0.879606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121700</td>\n",
       "      <td>0.192943</td>\n",
       "      <td>0.932994</td>\n",
       "      <td>0.898237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/84 [00:05<07:29,  5.42s/it]\u001b[A\n",
      "  2%|â–         | 2/84 [00:10<07:06,  5.20s/it]\u001b[A\n",
      "  4%|â–Ž         | 3/84 [00:15<06:56,  5.15s/it]\u001b[A\n",
      "  5%|â–         | 4/84 [00:20<06:48,  5.11s/it]\u001b[A\n",
      "  6%|â–Œ         | 5/84 [00:25<06:42,  5.09s/it]\u001b[A\n",
      "  7%|â–‹         | 6/84 [00:30<06:36,  5.08s/it]\u001b[A\n",
      "  8%|â–Š         | 7/84 [00:35<06:30,  5.08s/it]\u001b[A\n",
      " 10%|â–‰         | 8/84 [00:40<06:25,  5.07s/it]\u001b[A\n",
      " 11%|â–ˆ         | 9/84 [00:45<06:20,  5.07s/it]\u001b[A\n",
      " 12%|â–ˆâ–        | 10/84 [00:50<06:15,  5.07s/it]\u001b[A\n",
      " 13%|â–ˆâ–Ž        | 11/84 [00:56<06:10,  5.07s/it]\u001b[A\n",
      " 14%|â–ˆâ–        | 12/84 [01:01<06:05,  5.08s/it]\u001b[A\n",
      " 15%|â–ˆâ–Œ        | 13/84 [01:06<06:00,  5.08s/it]\u001b[A\n",
      " 17%|â–ˆâ–‹        | 14/84 [01:11<05:56,  5.09s/it]\u001b[A\n",
      " 18%|â–ˆâ–Š        | 15/84 [01:16<05:50,  5.08s/it]\u001b[A\n",
      " 19%|â–ˆâ–‰        | 16/84 [01:21<05:45,  5.08s/it]\u001b[A\n",
      " 20%|â–ˆâ–ˆ        | 17/84 [01:26<05:40,  5.09s/it]\u001b[A\n",
      " 21%|â–ˆâ–ˆâ–       | 18/84 [01:31<05:35,  5.09s/it]\u001b[A\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 19/84 [01:36<05:30,  5.08s/it]\u001b[A\n",
      " 24%|â–ˆâ–ˆâ–       | 20/84 [01:41<05:25,  5.08s/it]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 21/84 [01:46<05:20,  5.09s/it]\u001b[A\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 22/84 [01:52<05:15,  5.08s/it]\u001b[A\n",
      " 27%|â–ˆâ–ˆâ–‹       | 23/84 [01:57<05:10,  5.09s/it]\u001b[A\n",
      " 29%|â–ˆâ–ˆâ–Š       | 24/84 [02:02<05:05,  5.10s/it]\u001b[A\n",
      " 30%|â–ˆâ–ˆâ–‰       | 25/84 [02:07<05:00,  5.09s/it]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 26/84 [02:12<04:55,  5.09s/it]\u001b[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 27/84 [02:17<04:49,  5.09s/it]\u001b[A\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 28/84 [02:22<04:45,  5.09s/it]\u001b[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 29/84 [02:27<04:39,  5.09s/it]\u001b[A\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 30/84 [02:32<04:34,  5.09s/it]\u001b[A\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 31/84 [02:37<04:29,  5.09s/it]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 32/84 [02:42<04:24,  5.09s/it]\u001b[A\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 33/84 [02:48<04:19,  5.09s/it]\u001b[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 34/84 [02:53<04:14,  5.08s/it]\u001b[A\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/84 [02:58<04:09,  5.09s/it]\u001b[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 36/84 [03:03<04:04,  5.09s/it]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 37/84 [03:08<03:59,  5.09s/it]\u001b[A\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 38/84 [03:13<03:54,  5.10s/it]\u001b[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 39/84 [03:18<03:49,  5.09s/it]\u001b[A\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 40/84 [03:23<03:44,  5.09s/it]\u001b[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 41/84 [03:28<03:38,  5.09s/it]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 42/84 [03:33<03:33,  5.09s/it]\u001b[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 43/84 [03:38<03:28,  5.08s/it]\u001b[A\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/84 [03:43<03:23,  5.09s/it]\u001b[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 45/84 [03:49<03:18,  5.09s/it]\u001b[A\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 46/84 [03:54<03:13,  5.09s/it]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 47/84 [03:59<03:08,  5.08s/it]\u001b[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 48/84 [04:04<03:05,  5.16s/it]\u001b[A\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 49/84 [04:09<02:59,  5.13s/it]\u001b[A\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 50/84 [04:14<02:53,  5.11s/it]\u001b[A\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 51/84 [04:19<02:48,  5.11s/it]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/84 [04:24<02:43,  5.10s/it]\u001b[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 53/84 [04:29<02:37,  5.09s/it]\u001b[A\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 54/84 [04:35<02:32,  5.09s/it]\u001b[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 55/84 [04:40<02:27,  5.08s/it]\u001b[A\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 56/84 [04:45<02:22,  5.08s/it]\u001b[A\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 57/84 [04:50<02:17,  5.08s/it]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 58/84 [04:55<02:12,  5.08s/it]\u001b[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 59/84 [05:00<02:06,  5.08s/it]\u001b[A\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 60/84 [05:05<02:02,  5.09s/it]\u001b[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 61/84 [05:10<01:56,  5.08s/it]\u001b[A\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 62/84 [05:15<01:51,  5.08s/it]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 63/84 [05:20<01:46,  5.09s/it]\u001b[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 64/84 [05:25<01:41,  5.09s/it]\u001b[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 65/84 [05:30<01:36,  5.09s/it]\u001b[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 66/84 [05:36<01:31,  5.08s/it]\u001b[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 67/84 [05:41<01:26,  5.09s/it]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 68/84 [05:46<01:21,  5.08s/it]\u001b[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 69/84 [05:51<01:16,  5.09s/it]\u001b[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 70/84 [05:56<01:11,  5.09s/it]\u001b[A\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 71/84 [06:01<01:06,  5.09s/it]\u001b[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 72/84 [06:06<01:01,  5.09s/it]\u001b[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 73/84 [06:11<00:55,  5.08s/it]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 74/84 [06:16<00:50,  5.09s/it]\u001b[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 75/84 [06:21<00:45,  5.09s/it]\u001b[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 76/84 [06:26<00:40,  5.09s/it]\u001b[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 77/84 [06:31<00:35,  5.08s/it]\u001b[A\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 78/84 [06:37<00:30,  5.09s/it]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 79/84 [06:42<00:25,  5.09s/it]\u001b[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 80/84 [06:47<00:20,  5.09s/it]\u001b[A\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 81/84 [06:52<00:15,  5.09s/it]\u001b[A\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 82/84 [06:57<00:10,  5.09s/it]\u001b[A\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 83/84 [07:02<00:05,  5.09s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [07:05<00:00,  5.07s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [3:34:37<00:00, 12877.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "output_prefix = \"prepared_hsc\"\n",
    "\n",
    "n_hyperopt_trials = 0\n",
    "\n",
    "all_metrics = cc.validate(model_directory=model_path,\n",
    "                          prepared_input_data_file=f\"{output_dir}/{output_prefix}_labeled_train.dataset\",\n",
    "                          id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "                          output_directory=output_dir,\n",
    "                          n_hyperopt_trials=n_hyperopt_trials,\n",
    "                          output_prefix=output_prefix)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4e189f-0ed3-4256-9133-5e48bd88f96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8aecc-befa-4596-b825-01200b3ee6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0264e5d-1dda-4ca4-9855-f115caa7f160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1a62f-299d-43b8-aabb-dc55fb39c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe8b29-dd8f-4bf8-82c1-53196d73ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_id_split_dict = {\"attr_key\": \"individual\",\n",
    "                            \"train\": train_ids,\n",
    "                            \"eval\": eval_ids}\n",
    "\n",
    "# 6 layer Geneformer: https://huggingface.co/ctheodoris/Geneformer/blob/main/model.safetensors\n",
    "all_metrics = cc.validate(model_directory=\"/path/to/Geneformer\",\n",
    "                          prepared_input_data_file=f\"{output_dir}/{output_prefix}_labeled_train.dataset\",\n",
    "                          id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "                          output_directory=output_dir,\n",
    "                          output_prefix=output_prefix,\n",
    "                          split_id_dict=train_valid_id_split_dict)\n",
    "                          # to optimize hyperparameters, set n_hyperopt_trials=100 (or alternative desired # of trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca8ab4-6f4d-4dd6-9b90-edfb5cc7417c",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580021e-2b70-4ebc-943c-2bfe6177e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = Classifier(classifier=\"cell\",\n",
    "                cell_state_dict = {\"state_key\": \"disease\", \"states\": \"all\"},\n",
    "                forward_batch_size=200,\n",
    "                nproc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05398b4-bca1-44b0-8160-637489f16646",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_test = cc.evaluate_saved_model(\n",
    "        model_directory=f\"{output_dir}/{datestamp_min}_geneformer_cellClassifier_{output_prefix}/ksplit1/\",\n",
    "        id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "        test_data_file=f\"{output_dir}/{output_prefix}_labeled_test.dataset\",\n",
    "        output_directory=output_dir,\n",
    "        output_prefix=output_prefix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45404e4-87cc-421d-84f5-1f9cbc09aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_conf_mat(\n",
    "        conf_mat_dict={\"Geneformer\": all_metrics_test[\"conf_matrix\"]},\n",
    "        output_directory=output_dir,\n",
    "        output_prefix=output_prefix,\n",
    "        custom_class_order=[\"nf\",\"hcm\",\"dcm\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038d701-ab94-46d2-b390-803be0850019",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_predictions(\n",
    "    predictions_file=f\"{output_dir}/{output_prefix}_pred_dict.pkl\",\n",
    "    id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "    title=\"disease\",\n",
    "    output_directory=output_dir,\n",
    "    output_prefix=output_prefix,\n",
    "    custom_class_order=[\"nf\",\"hcm\",\"dcm\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
