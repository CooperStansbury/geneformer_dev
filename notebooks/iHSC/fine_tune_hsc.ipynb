{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a2b29a-c678-4874-a1bf-5af3a7d00ed9",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Classification of Cardiomyopathy Disease States\n",
    "Please note that, as usual with deep learning models, we **highly** recommend tuning learning hyperparameters for all fine-tuning applications as this can significantly improve model performance. Example below uses previously optimized hyperparameters, but one can optimize hyperparameters with the argument n_hyperopt_trials=n in cc.validate() where n>0 and represents the number of trials for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe3b79b-aa8f-416c-9755-7f9299d6a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORES=40\n",
      "GPUS=3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from geneformer import Classifier\n",
    "\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import load_dataset\n",
    "from geneformer import EmbExtractor\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(0, '../../scripts/')\n",
    "import geneformer_utils as gtu\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "CORES = os.cpu_count()\n",
    "GPUS = torch.cuda.device_count()\n",
    "print(f\"{CORES=}\")\n",
    "print(f\"{GPUS=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d15eaf9-f42b-4999-9f8c-7d70758fc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpath = \"/scratch/indikar_root/indikar1/shared_data/geneformer/datasets/\"\n",
    "\n",
    "\n",
    "# def load_data(path, sample_size=None):\n",
    "#     \"\"\"\n",
    "#     Loads data from a file, processes cell types, and returns a DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         path (str): The path to the dataset file.\n",
    "#         sample_size (int, optional): Number of cells to sample. Defaults to None.\n",
    "#     Returns:\n",
    "#         pandas.DataFrame: The processed DataFrame.\n",
    "#     \"\"\"\n",
    "\n",
    "#     df = gtu.load_data_as_dataframe(path, num_cells=sample_size, shuffle=True)\n",
    "\n",
    "#     if \"iHSC\" in path:\n",
    "#         df['cell_type'] = \"iHSC\"\n",
    "#     elif \"pellin\" in path:\n",
    "#         df['cell_type'] = df['dataset']\n",
    "#     elif \"weng\" in path:\n",
    "#         df['cell_type'] = df['STD.CellType']\n",
    "#     else:\n",
    "#         df['cell_type'] = df['free_annotation']\n",
    "\n",
    "#     # Extract basename without extension and assign to 'dataset' column\n",
    "#     df['dataset'] = os.path.splitext(os.path.basename(path))[0]\n",
    "#     df = df[['input_ids', 'cell_type', 'dataset', 'length']]\n",
    "\n",
    "#     return df\n",
    "\n",
    "# sample_size = None\n",
    "\n",
    "# df = []\n",
    "\n",
    "# for dataset in os.listdir(dpath):\n",
    "#     print(f\"{dataset=}\")\n",
    "#     data_path = f\"{dpath}{dataset}\"\n",
    "#     tmp = load_data(data_path, sample_size)\n",
    "    \n",
    "#     df.append(tmp)\n",
    "    \n",
    "# df = pd.concat(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fbc26c-b2cb-4483-a209-285b3835b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpath = \"../ihsc_cell_types.csv\"\n",
    "# cell_map = pd.read_csv(fpath, comment=\"#\")\n",
    "\n",
    "# df = pd.merge(df, \n",
    "#               cell_map,\n",
    "#               how='left',\n",
    "#               left_on='cell_type',\n",
    "#               right_on='label',\n",
    "# )\n",
    "\n",
    "# df = df.rename(columns={'label' : 'ignore'})\n",
    "\n",
    "# df = df[df['standardized_cell_type'].notna()]\n",
    "# print(f\"{df.shape=}\")\n",
    "# print()\n",
    "# print(df['standardized_cell_type'].value_counts())\n",
    "# print()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46e4cc-9bbf-41d0-9039-3dc76d7c99cd",
   "metadata": {},
   "source": [
    "# save the data to disk to make it easier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2b9d87-00c4-4708-b8c2-5d904b7f5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_output_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "\n",
    "# data = Dataset.from_pandas(df)\n",
    "# data.save_to_disk(data_output_path)\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a887a-36d7-433c-9074-46322bcaf023",
   "metadata": {},
   "source": [
    "# Set up the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3d8a2f-0e77-4524-a029-bb34ed1b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"num_train_epochs\" : 0.9,\n",
    "    \"lr_scheduler_type\" : \"polynomial\",\n",
    "    \"per_device_train_batch_size\" : 20,\n",
    "    \"seed\" : 73,\n",
    "    \"learning_rate\" : 0.000804,\n",
    "    \"warmup_steps\" : 1812,\n",
    "    \"weight_decay\" : 0.258828,\n",
    "}\n",
    "\n",
    "cell_state_dict = {\n",
    "    \"state_key\" : \"standardized_cell_type\", \n",
    "     \"states\" : \"all\",\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sample_size = None\n",
    "\n",
    "cc = Classifier(classifier = \"cell\",\n",
    "                cell_state_dict = cell_state_dict,\n",
    "                training_args = training_args,\n",
    "                max_ncells = sample_size,\n",
    "                freeze_layers = 2,\n",
    "                num_crossval_splits = 1,\n",
    "                forward_batch_size = 200,\n",
    "                nproc = CORES,\n",
    "                ngpu = GPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1f146-e8e9-4160-8b60-239a3e3c7037",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d10d0a-dba4-4d66-a3d7-abbac2a0ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_output_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "# output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "# output_prefix = \"prepared_hsc\"\n",
    "\n",
    "# cc.prepare_data(input_data_file=data_output_path,\n",
    "#                 output_directory=output_dir,\n",
    "#                 output_prefix=output_prefix,\n",
    "#                 test_size=0.3)\n",
    "\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20bd09c4-5231-43f0-aedd-493e72fa5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d01ad-303e-4291-94ec-6a5b34437087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# with profile(\n",
    "#     activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "#     record_shapes=True,\n",
    "#     profile_memory=True,  \n",
    "#     with_stack=True  \n",
    "# ) as prof:\n",
    "#     with record_function(\"model_inference\"):\n",
    "#         # Your training loop code here \n",
    "\n",
    "# print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))  # View top 10 GPU operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a849397a-1727-497f-87bb-e56908cc2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240711_geneformer_cellClassifier_prepared_hsc/â€™: File exists\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation split: 1/1 ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240711_geneformer_cellClassifier_prepared_hsc/ksplit1â€™: File exists\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2005' max='2005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2005/2005 2:57:08, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>0.237481</td>\n",
       "      <td>0.915389</td>\n",
       "      <td>0.843410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "  0%|          | 0/84 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/84 [00:22<31:09, 22.53s/it]\u001b[A\n",
      "  2%|â–         | 2/84 [00:32<20:46, 15.20s/it]\u001b[A\n",
      "  4%|â–Ž         | 3/84 [00:39<15:08, 11.22s/it]\u001b[A\n",
      "  5%|â–         | 4/84 [00:44<12:04,  9.06s/it]\u001b[A\n",
      "  6%|â–Œ         | 5/84 [00:50<10:11,  7.73s/it]\u001b[A\n",
      "  7%|â–‹         | 6/84 [00:55<09:03,  6.97s/it]\u001b[A\n",
      "  8%|â–Š         | 7/84 [01:01<08:21,  6.51s/it]\u001b[A\n",
      " 10%|â–‰         | 8/84 [01:06<07:45,  6.13s/it]\u001b[A\n",
      " 11%|â–ˆ         | 9/84 [01:11<07:20,  5.87s/it]\u001b[A\n",
      " 12%|â–ˆâ–        | 10/84 [01:17<07:01,  5.70s/it]\u001b[A\n",
      " 13%|â–ˆâ–Ž        | 11/84 [01:22<06:48,  5.59s/it]\u001b[A\n",
      " 14%|â–ˆâ–        | 12/84 [01:27<06:37,  5.53s/it]\u001b[A\n",
      " 15%|â–ˆâ–Œ        | 13/84 [01:33<06:29,  5.48s/it]\u001b[A\n",
      " 17%|â–ˆâ–‹        | 14/84 [01:38<06:21,  5.44s/it]\u001b[A\n",
      " 18%|â–ˆâ–Š        | 15/84 [01:44<06:14,  5.42s/it]\u001b[A\n",
      " 19%|â–ˆâ–‰        | 16/84 [01:49<06:08,  5.43s/it]\u001b[A\n",
      " 20%|â–ˆâ–ˆ        | 17/84 [01:54<06:02,  5.41s/it]\u001b[A\n",
      " 21%|â–ˆâ–ˆâ–       | 18/84 [02:00<05:55,  5.39s/it]\u001b[A\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 19/84 [02:05<05:49,  5.38s/it]\u001b[A\n",
      " 24%|â–ˆâ–ˆâ–       | 20/84 [02:10<05:44,  5.39s/it]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 21/84 [02:16<05:39,  5.39s/it]\u001b[A\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 22/84 [02:21<05:33,  5.38s/it]\u001b[A\n",
      " 27%|â–ˆâ–ˆâ–‹       | 23/84 [02:27<05:28,  5.38s/it]\u001b[A\n",
      " 29%|â–ˆâ–ˆâ–Š       | 24/84 [02:32<05:22,  5.38s/it]\u001b[A\n",
      " 30%|â–ˆâ–ˆâ–‰       | 25/84 [02:37<05:17,  5.39s/it]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 26/84 [02:43<05:11,  5.38s/it]\u001b[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 27/84 [02:48<05:05,  5.37s/it]\u001b[A\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 28/84 [02:53<04:59,  5.35s/it]\u001b[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 29/84 [02:59<04:53,  5.33s/it]\u001b[A\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 30/84 [03:04<04:47,  5.33s/it]\u001b[A\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 31/84 [03:09<04:41,  5.31s/it]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 32/84 [03:15<04:36,  5.31s/it]\u001b[A\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 33/84 [03:20<04:37,  5.43s/it]\u001b[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 34/84 [03:26<04:30,  5.41s/it]\u001b[A\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/84 [03:31<04:23,  5.38s/it]\u001b[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 36/84 [03:36<04:17,  5.36s/it]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 37/84 [03:42<04:11,  5.35s/it]\u001b[A\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 38/84 [03:47<04:06,  5.35s/it]\u001b[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 39/84 [03:52<04:00,  5.33s/it]\u001b[A\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 40/84 [03:58<03:54,  5.34s/it]\u001b[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 41/84 [04:03<03:49,  5.33s/it]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 42/84 [04:08<03:43,  5.33s/it]\u001b[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 43/84 [04:13<03:37,  5.32s/it]\u001b[A\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 44/84 [04:19<03:32,  5.31s/it]\u001b[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 45/84 [04:24<03:27,  5.33s/it]\u001b[A\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 46/84 [04:29<03:22,  5.33s/it]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 47/84 [04:35<03:16,  5.32s/it]\u001b[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 48/84 [04:40<03:11,  5.32s/it]\u001b[A\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 49/84 [04:45<03:05,  5.31s/it]\u001b[A\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 50/84 [04:51<03:00,  5.31s/it]\u001b[A\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 51/84 [04:56<02:55,  5.31s/it]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 52/84 [05:01<02:50,  5.32s/it]\u001b[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 53/84 [05:07<02:45,  5.33s/it]\u001b[A\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 54/84 [05:12<02:39,  5.32s/it]\u001b[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 55/84 [05:17<02:34,  5.32s/it]\u001b[A\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 56/84 [05:23<02:28,  5.32s/it]\u001b[A\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 57/84 [05:28<02:23,  5.31s/it]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 58/84 [05:33<02:18,  5.32s/it]\u001b[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 59/84 [05:39<02:13,  5.33s/it]\u001b[A\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 60/84 [05:44<02:07,  5.32s/it]\u001b[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 61/84 [05:49<02:02,  5.32s/it]\u001b[A\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 62/84 [05:55<01:56,  5.31s/it]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 63/84 [06:00<01:51,  5.32s/it]\u001b[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 64/84 [06:05<01:46,  5.31s/it]\u001b[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 65/84 [06:11<01:41,  5.32s/it]\u001b[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 66/84 [06:16<01:35,  5.33s/it]\u001b[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 67/84 [06:21<01:30,  5.33s/it]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 68/84 [06:27<01:25,  5.33s/it]\u001b[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 69/84 [06:32<01:19,  5.33s/it]\u001b[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 70/84 [06:37<01:14,  5.31s/it]\u001b[A\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 71/84 [06:42<01:09,  5.32s/it]\u001b[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 72/84 [06:48<01:03,  5.32s/it]\u001b[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 73/84 [06:53<00:58,  5.30s/it]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 74/84 [06:58<00:53,  5.30s/it]\u001b[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 75/84 [07:04<00:47,  5.31s/it]\u001b[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 76/84 [07:09<00:42,  5.31s/it]\u001b[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 77/84 [07:14<00:37,  5.32s/it]\u001b[A\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 78/84 [07:20<00:31,  5.31s/it]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 79/84 [07:25<00:26,  5.31s/it]\u001b[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 80/84 [07:30<00:21,  5.30s/it]\u001b[A\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 81/84 [07:35<00:15,  5.29s/it]\u001b[A\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 82/84 [07:41<00:10,  5.29s/it]\u001b[A\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 83/84 [07:46<00:05,  5.29s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [07:49<00:00,  5.59s/it]\u001b[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [3:05:30<00:00, 11130.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "output_prefix = \"prepared_hsc\"\n",
    "\n",
    "n_hyperopt_trials = 0\n",
    "\n",
    "all_metrics = cc.validate(model_directory=model_path,\n",
    "                          prepared_input_data_file=f\"{output_dir}/{output_prefix}_labeled_train.dataset\",\n",
    "                          id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "                          output_directory=output_dir,\n",
    "                          n_hyperopt_trials=n_hyperopt_trials,\n",
    "                          output_prefix=output_prefix)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4e189f-0ed3-4256-9133-5e48bd88f96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8aecc-befa-4596-b825-01200b3ee6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0264e5d-1dda-4ca4-9855-f115caa7f160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1a62f-299d-43b8-aabb-dc55fb39c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe8b29-dd8f-4bf8-82c1-53196d73ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_id_split_dict = {\"attr_key\": \"individual\",\n",
    "                            \"train\": train_ids,\n",
    "                            \"eval\": eval_ids}\n",
    "\n",
    "# 6 layer Geneformer: https://huggingface.co/ctheodoris/Geneformer/blob/main/model.safetensors\n",
    "all_metrics = cc.validate(model_directory=\"/path/to/Geneformer\",\n",
    "                          prepared_input_data_file=f\"{output_dir}/{output_prefix}_labeled_train.dataset\",\n",
    "                          id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "                          output_directory=output_dir,\n",
    "                          output_prefix=output_prefix,\n",
    "                          split_id_dict=train_valid_id_split_dict)\n",
    "                          # to optimize hyperparameters, set n_hyperopt_trials=100 (or alternative desired # of trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca8ab4-6f4d-4dd6-9b90-edfb5cc7417c",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580021e-2b70-4ebc-943c-2bfe6177e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = Classifier(classifier=\"cell\",\n",
    "                cell_state_dict = {\"state_key\": \"disease\", \"states\": \"all\"},\n",
    "                forward_batch_size=200,\n",
    "                nproc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05398b4-bca1-44b0-8160-637489f16646",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_test = cc.evaluate_saved_model(\n",
    "        model_directory=f\"{output_dir}/{datestamp_min}_geneformer_cellClassifier_{output_prefix}/ksplit1/\",\n",
    "        id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "        test_data_file=f\"{output_dir}/{output_prefix}_labeled_test.dataset\",\n",
    "        output_directory=output_dir,\n",
    "        output_prefix=output_prefix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45404e4-87cc-421d-84f5-1f9cbc09aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_conf_mat(\n",
    "        conf_mat_dict={\"Geneformer\": all_metrics_test[\"conf_matrix\"]},\n",
    "        output_directory=output_dir,\n",
    "        output_prefix=output_prefix,\n",
    "        custom_class_order=[\"nf\",\"hcm\",\"dcm\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0038d701-ab94-46d2-b390-803be0850019",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.plot_predictions(\n",
    "    predictions_file=f\"{output_dir}/{output_prefix}_pred_dict.pkl\",\n",
    "    id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "    title=\"disease\",\n",
    "    output_directory=output_dir,\n",
    "    output_prefix=output_prefix,\n",
    "    custom_class_order=[\"nf\",\"hcm\",\"dcm\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
