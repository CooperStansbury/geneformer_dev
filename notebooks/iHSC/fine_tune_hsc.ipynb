{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a2b29a-c678-4874-a1bf-5af3a7d00ed9",
   "metadata": {},
   "source": [
    "## Geneformer Fine-Tuning for Classification of Cardiomyopathy Disease States\n",
    "Please note that, as usual with deep learning models, we **highly** recommend tuning learning hyperparameters for all fine-tuning applications as this can significantly improve model performance. Example below uses previously optimized hyperparameters, but one can optimize hyperparameters with the argument n_hyperopt_trials=n in cc.validate() where n>0 and represents the number of trials for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe3b79b-aa8f-416c-9755-7f9299d6a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORES=40\n",
      "GPUS=3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from geneformer import Classifier\n",
    "\n",
    "from datasets import Dataset, load_from_disk\n",
    "from datasets import load_dataset\n",
    "from geneformer import EmbExtractor\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(0, '../../scripts/')\n",
    "import geneformer_utils as gtu\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "CORES = os.cpu_count()\n",
    "GPUS = torch.cuda.device_count()\n",
    "print(f\"{CORES=}\")\n",
    "print(f\"{GPUS=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c46e4cc-9bbf-41d0-9039-3dc76d7c99cd",
   "metadata": {},
   "source": [
    "# load the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2b9d87-00c4-4708-b8c2-5d904b7f5e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'cell_type', 'dataset', 'length', 'ignore', 'standardized_cell_type', 'broad_type', '__index_level_0__'],\n",
       "    num_rows: 214715\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "\n",
    "data = load_from_disk(data_path)\n",
    "cell_types = data.unique(\"standardized_cell_type\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a5469b-c420-4ef0-943a-8fea5bbcce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B Cell',\n",
       " 'Common Myeloid Progenitor',\n",
       " 'Granulocyte-Macrophage Progenitor',\n",
       " 'HSC',\n",
       " 'T Cell',\n",
       " 'Megakaryocyte-Erythroid Progenitor',\n",
       " 'Plasma Cell',\n",
       " 'Monocyte',\n",
       " 'Multipotent Progenitor',\n",
       " 'Dendritic Cell',\n",
       " 'Common Lymphoid Progenitor',\n",
       " 'NK Cell',\n",
       " 'Multi-Lymphoid Progenitor',\n",
       " 'Fibroblast',\n",
       " 'Macrophage',\n",
       " 'Endothelial Cell',\n",
       " 'Smooth Muscle Cell',\n",
       " 'Mast Cell',\n",
       " 'Erythrocyte',\n",
       " 'Neutrophil',\n",
       " 'NK T Cell',\n",
       " 'Granulocyte']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in cell_types if not \"iHSC\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a887a-36d7-433c-9074-46322bcaf023",
   "metadata": {},
   "source": [
    "# Set up the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3d8a2f-0e77-4524-a029-bb34ed1b4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data_dict = {\n",
    "    \"standardized_cell_type\": [x for x in cell_types if not \"iHSC\" in x], \n",
    "}\n",
    "    \n",
    "training_args = {\n",
    "    \"num_train_epochs\" : 3,\n",
    "    \"lr_scheduler_type\" : \"polynomial\",\n",
    "    \"per_device_train_batch_size\" : 20,\n",
    "    \"seed\" : 73,\n",
    "    \"learning_rate\" : 0.000804,\n",
    "    \"warmup_steps\" : 1812,\n",
    "    \"weight_decay\" : 0.258828,\n",
    "}\n",
    "\n",
    "cell_state_dict = {\n",
    "    \"state_key\" : \"standardized_cell_type\", \n",
    "    \"states\" : \"all\",\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "sample_size = None\n",
    "\n",
    "cc = Classifier(classifier = \"cell\",\n",
    "                cell_state_dict = cell_state_dict,\n",
    "                training_args = training_args,\n",
    "                filter_data=filter_data_dict,\n",
    "                max_ncells = sample_size,\n",
    "                freeze_layers = 2,\n",
    "                num_crossval_splits = 1,\n",
    "                forward_batch_size = 200,\n",
    "                nproc = CORES,\n",
    "                ngpu = GPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1f146-e8e9-4160-8b60-239a3e3c7037",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d10d0a-dba4-4d66-a3d7-abbac2a0ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=40): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206141/206141 [04:56<00:00, 696.22 examples/s]  \n",
      "Saving the dataset (2/2 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144298/144298 [1:25:12<00:00, 28.22 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61843/61843 [20:57<00:00, 49.19 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_output_path = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/hsc.dataset\"\n",
    "output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "output_prefix = \"no_induced\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "cc.prepare_data(input_data_file=data_output_path,\n",
    "                output_directory=output_dir,\n",
    "                output_prefix=output_prefix,\n",
    "                test_size=0.3)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20bd09c4-5231-43f0-aedd-493e72fa5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24b15a-1fee-4bd3-8a02-079722bdaa1c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849397a-1727-497f-87bb-e56908cc2740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240715_geneformer_cellClassifier_no_induced/â€™: File exists\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]mkdir: cannot create directory â€˜/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/240715_geneformer_cellClassifier_no_induced/ksplit1â€™: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation split: 1/1 ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6128' max='6414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6128/6414 3:44:59 < 10:30, 0.45 it/s, Epoch 2.87/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.297368</td>\n",
       "      <td>0.897468</td>\n",
       "      <td>0.799918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.238160</td>\n",
       "      <td>0.917613</td>\n",
       "      <td>0.845888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/geneformer/collator_for_classification.py:581: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "/home/cstansbu/miniconda3/envs/geneformer/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "output_dir = \"/scratch/indikar_root/indikar1/shared_data/geneformer/fine_tune/\"\n",
    "output_prefix = \"no_induced\"\n",
    "\n",
    "n_hyperopt_trials = 0\n",
    "\n",
    "all_metrics = cc.validate(model_directory=model_path,\n",
    "                          prepared_input_data_file=f\"{output_dir}/{output_prefix}_labeled_train.dataset\",\n",
    "                          id_class_dict_file=f\"{output_dir}/{output_prefix}_id_class_dict.pkl\",\n",
    "                          output_directory=output_dir,\n",
    "                          n_hyperopt_trials=n_hyperopt_trials,\n",
    "                          output_prefix=output_prefix)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e189f-0ed3-4256-9133-5e48bd88f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
