{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7438cfd2-e3c9-443e-945d-fdcb23a03fec",
   "metadata": {},
   "source": [
    "# AnnData -> GeneFormerEmbeddings -> AnnData\n",
    "\n",
    "In this file Joshua changes a file made by cooper to standardize the time point and replicate naming from files made by cooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452594b5-14e9-4259-9544-94cb6b1090de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe344b3-3ade-4387-b317-42fb87cacf4e",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d68673-d176-4fe8-8bce-a2fe3f4de74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/jpic/geneformer_dev/scripts')\n",
    "import geneformer_utils as gtu\n",
    "\n",
    "def main(input_file=None, output_directory=None, verbose=True):\n",
    "\n",
    "    input_path  = input_file\n",
    "    base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    output_path = os.path.join(output_directory, base_name + '.dataset')\n",
    "    outpath = os.path.join(output_directory, base_name + '.h5ad')\n",
    "    \n",
    "    # Default values\n",
    "    MODEL_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "    DEFAULT_NAME_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_name_id_dict.pkl\"\n",
    "    DEFAULT_TOKEN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/token_dictionary.pkl\"\n",
    "    DEFAULT_MEDIAN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_median_dictionary.pkl\"\n",
    "    MODEL_INPUT_SIZE = 2048\n",
    "    NUMBER_PROC = 16\n",
    "    TARGET_SUM = 10000\n",
    "    GENE_ID = 'ensembl_id'\n",
    "    COUNTS_COLUMN = 'n_counts'\n",
    "    LAYER = 'X'\n",
    "    GENE_NAME_COLUMN = 'gene_name'\n",
    "\n",
    "    # set values used for embedding\n",
    "    token_path  = DEFAULT_TOKEN_PATH\n",
    "    median_path = DEFAULT_MEDIAN_PATH\n",
    "    n_proc      = NUMBER_PROC\n",
    "    model_size  = MODEL_INPUT_SIZE\n",
    "    target_sum  = TARGET_SUM\n",
    "    gene_id     = GENE_ID\n",
    "    aggregate_transcripts = False\n",
    "    counts_column = COUNTS_COLUMN\n",
    "    layer       = LAYER\n",
    "    gene_names  = DEFAULT_NAME_PATH\n",
    "    gene_name_column = GENE_NAME_COLUMN\n",
    "    map_names   = False\n",
    "    num_cells   = None # all cells, useful for testing \n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    #\n",
    "    #   TOKENIZE COUNTS DATA FOR GENEFORMER\n",
    "    #\n",
    "    ###########################################\n",
    "    print(\"Loading gene tokenization data...\") if verbose else None\n",
    "    gene_token_dict, gene_keys, genelist_dict = load_gene_tokenization(token_path)\n",
    "    print(f\"Loaded {len(gene_token_dict)} gene tokens\") if verbose else None\n",
    "    \n",
    "    print(\"Loading gene median expression data...\") if verbose else None\n",
    "    gene_median_dict = load_gene_median_dict(median_path)\n",
    "    print(f\"Loaded {len(gene_median_dict)} gene median expression values\") if verbose else None\n",
    "    \n",
    "    if map_names:\n",
    "        print(\"Loading gene name mapping data...\") if verbose else None\n",
    "        gene_names = load_gene_names(gene_names)\n",
    "        print(f\"Loaded {len(gene_names)} gene name mappings\") if verbose else None\n",
    "    \n",
    "    # Load and pre-process data\n",
    "    print(f\"Loading AnnData from {input_path}...\") if verbose else None\n",
    "    adata = sc.read_h5ad(input_path)\n",
    "    print(f\"Loaded AnnData with shape {adata.shape}\") if verbose else None\n",
    "    \n",
    "    if map_names:\n",
    "        print(\"Mapping gene names to Ensembl IDs...\") if verbose else None\n",
    "        adata = map_gene_names(adata, gene_id, gene_name_column, gene_names)\n",
    "    \n",
    "    if not layer == 'X':\n",
    "        print(f\"Using layer '{layer}' for expression data...\") if verbose else None\n",
    "        adata.X = adata.layers[layer]\n",
    "        \n",
    "    print(\"Checking for and/or calculating total counts per cell...\") if verbose else None\n",
    "    adata = check_counts_column(adata, counts_column)\n",
    "    \n",
    "    # Tokenize and rank genes\n",
    "    print(\"Tokenizing and ranking genes...\") if verbose else None\n",
    "    tokenized_cells, cell_metadata = tokenize_anndata(\n",
    "        adata, genelist_dict, gene_median_dict,\n",
    "        target_sum=target_sum, gene_id=gene_id, counts_column=counts_column\n",
    "    )\n",
    "    print(f\"Processed {len(tokenized_cells)} cells\") if verbose else None\n",
    "    \n",
    "    # Create Hugging Face dataset\n",
    "    print(\"Creating Hugging Face dataset...\") if verbose else None\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": tokenized_cells,\n",
    "        **cell_metadata\n",
    "    }\n",
    "    output_dataset = Dataset.from_dict(dataset_dict)\n",
    "    print(f\"Dataset has {len(output_dataset)} examples\") if verbose else None\n",
    "    \n",
    "    # Format cell features\n",
    "    print(\"Formatting cell features...\") if verbose else None\n",
    "    dataset = output_dataset.map(format_cell_features, num_proc=n_proc)\n",
    "    \n",
    "    # Save dataset\n",
    "    print(f\"Saving processed dataset to {output_path}...\") if verbose else None\n",
    "    \n",
    "    save_hf_dataset(dataset, output_path, overwrite=True)\n",
    "    print(\"Processing completed successfully!\") if verbose else None\n",
    "\n",
    "    \n",
    "    ###########################################\n",
    "    #\n",
    "    #   EMBED TOKENS WITH GENEFORMER TO ANNDATA\n",
    "    #\n",
    "    ###########################################\n",
    "    dataset_path = output_path\n",
    "    \n",
    "    print(MODEL_PATH)\n",
    "    \n",
    "    print(f\"Loading model from '{MODEL_PATH}'...\") if verbose else None\n",
    "    model = gtu.load_model(MODEL_PATH)\n",
    "    print(\"Model loaded successfully!\") if verbose else None\n",
    "    \n",
    "    print(f\"Loading dataset from '{dataset_path}' (up to {num_cells} cells)...\") if verbose else None\n",
    "    try:\n",
    "        df = gtu.load_data_as_dataframe(dataset_path, num_cells=num_cells)\n",
    "        data = Dataset.from_pandas(df)\n",
    "        df = df.drop(columns='input_ids')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Dataset file not found at '{dataset_path}'\") if verbose else None\n",
    "        sys.exit(1)\n",
    "    except Exception as e:  # Catching other potential errors\n",
    "        print(f\"Error loading dataset: {e}\") if verbose else None\n",
    "        sys.exit(1)\n",
    "    print(\"Dataset loaded successfully!\") if verbose else None\n",
    "    \n",
    "    print(\"Extracting embeddings...\") if verbose else None\n",
    "    embs = gtu.extract_embedding_in_mem(model, data)\n",
    "    adata = gtu.embedding_to_adata(embs)\n",
    "    adata.obs = df.astype(str).reset_index().copy()\n",
    "    print(\"Embeddings extracted successfully!\") if verbose else None\n",
    "    \n",
    "    print(f\"Writing results to '{outpath}'...\") if verbose else None\n",
    "    try:\n",
    "        adata.write(outpath)\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output file: {e}\") if verbose else None\n",
    "        sys.exit(1)\n",
    "    print(\"Output file written successfully!\") if verbose else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21780a20-41b0-4900-9f87-65529c73e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gene tokenization data...\n",
      "Loaded 25426 gene tokens\n",
      "Loading gene median expression data...\n",
      "Loaded 25424 gene median expression values\n",
      "Loading AnnData from /nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad...\n",
      "Loaded AnnData with shape (66, 19393)\n",
      "Checking for and/or calculating total counts per cell...\n",
      "Tokenizing and ranking genes...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gene_token_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m arg_in  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m arg_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/nfs/turbo/umms-indikar/shared/projects/geneformer/data/test\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 88\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(input_file, output_directory, verbose)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Tokenize and rank genes\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizing and ranking genes...\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m tokenized_cells, cell_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_anndata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenelist_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_median_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_sum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgene_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgene_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounts_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounts_column\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tokenized_cells)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cells\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Create Hugging Face dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 166\u001b[0m, in \u001b[0;36mtokenize_anndata\u001b[0;34m(adata, genelist_dict, gene_median_dict, chunk_size, target_sum, counts_column, gene_id)\u001b[0m\n\u001b[1;32m    164\u001b[0m coding_miRNA_ids \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar[gene_id]\u001b[38;5;241m.\u001b[39miloc[coding_miRNA_loc]\n\u001b[1;32m    165\u001b[0m norm_factor_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([gene_median_dict[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m coding_miRNA_ids])\n\u001b[0;32m--> 166\u001b[0m coding_miRNA_tokens \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mgene_token_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoding_miRNA_ids\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    168\u001b[0m tokenized_cells \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    169\u001b[0m file_cell_metadata \u001b[38;5;241m=\u001b[39m {k: [] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m adata\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mcolumns}  \u001b[38;5;66;03m# Initialize metadata dict\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 166\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m coding_miRNA_ids \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mvar[gene_id]\u001b[38;5;241m.\u001b[39miloc[coding_miRNA_loc]\n\u001b[1;32m    165\u001b[0m norm_factor_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([gene_median_dict[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m coding_miRNA_ids])\n\u001b[0;32m--> 166\u001b[0m coding_miRNA_tokens \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mgene_token_dict\u001b[49m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m coding_miRNA_ids])\n\u001b[1;32m    168\u001b[0m tokenized_cells \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    169\u001b[0m file_cell_metadata \u001b[38;5;241m=\u001b[39m {k: [] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m adata\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mcolumns}  \u001b[38;5;66;03m# Initialize metadata dict\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gene_token_dict' is not defined"
     ]
    }
   ],
   "source": [
    "arg_in  = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad'\n",
    "arg_out = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/test'\n",
    "main(input_file=arg_in, output_directory=arg_out, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74cae0b4-fcf7-4952-8d42-fa948ecc22bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tokenize_anndata in module __main__:\n",
      "\n",
      "tokenize_anndata(adata, genelist_dict, gene_median_dict, chunk_size=100000, target_sum=10000, counts_column='n_counts', gene_id='ensembl_id')\n",
      "    Tokenizes and ranks genes within an AnnData object, optimizing for memory efficiency.\n",
      "    \n",
      "    This function processes gene expression data in chunks, applies normalization, and ranks genes\n",
      "    for each cell based on their expression levels. The resulting tokenized and ranked gene\n",
      "    representations, along with cell metadata, are returned.\n",
      "    \n",
      "    Args:\n",
      "        adata (AnnData): The AnnData object containing gene expression data.\n",
      "        genelist_dict (dict): Dictionary mapping gene IDs to boolean values indicating relevance.\n",
      "        gene_median_dict (dict): Dictionary mapping gene IDs to their median expression values.\n",
      "        chunk_size (int, optional): Number of cells to process in each chunk (default: 1000).\n",
      "        target_sum (int, optional): Target sum for count normalization (default: 10000).\n",
      "        counts_column (str, optional): The column in `adata.obs` containing cell counts (default: 'n_counts').\n",
      "        gene_id (str, optional): The column in `adata.var` containing gene IDs (default: 'ensembl_id').\n",
      "    \n",
      "    Returns:\n",
      "        tuple: \n",
      "            - list: List of tokenized and ranked gene lists for each cell.\n",
      "            - dict: Dictionary containing cell metadata (keys are metadata column names).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenize_anndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d0e6f8-020c-43c1-a399-bd10b61098c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_in  = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad'\n",
    "arg_out = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.dataset'\n",
    "arg_out2 = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic_GF_embeddings'\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b27f3-7352-4b0c-920c-cc78305a4c1b",
   "metadata": {},
   "source": [
    "## to_geneformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6013c8-1379-4728-816b-1575e299d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "import scanpy as sc\n",
    "import anndata as an\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c6d3b5-9571-4d44-a0d9-8d7d73074ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input arguments\n",
    "arg_in  = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad'\n",
    "arg_out = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.dataset'\n",
    "arg_out2 = '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic_GF_embeddings'\n",
    "arg_verbos = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981d1ff2-303c-4e49-ab74-f70909139a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values\n",
    "DEFAULT_NAME_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_name_id_dict.pkl\"\n",
    "DEFAULT_TOKEN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/token_dictionary.pkl\"\n",
    "DEFAULT_MEDIAN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_median_dictionary.pkl\"\n",
    "MODEL_INPUT_SIZE = 2048\n",
    "NUMBER_PROC = 16\n",
    "TARGET_SUM = 10000\n",
    "GENE_ID = 'ensembl_id'\n",
    "COUNTS_COLUMN = 'n_counts'\n",
    "LAYER = 'X'\n",
    "GENE_NAME_COLUMN = 'gene_name'\n",
    "\n",
    "input_path = arg_in\n",
    "output_path = arg_out\n",
    "token_path  = DEFAULT_TOKEN_PATH\n",
    "median_path = DEFAULT_MEDIAN_PATH\n",
    "n_proc      = NUMBER_PROC\n",
    "model_size  = MODEL_INPUT_SIZE\n",
    "target_sum  = TARGET_SUM\n",
    "gene_id     = GENE_ID\n",
    "aggregate_transcripts = False  # Default to False since it's an optional flag\n",
    "counts_column = COUNTS_COLUMN\n",
    "layer       = LAYER\n",
    "gene_names  = DEFAULT_NAME_PATH\n",
    "gene_name_column = GENE_NAME_COLUMN\n",
    "map_names   = False  # Default to False since it's an optional flag\n",
    "verbose     = arg_verbos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81630ea8-f4cd-4233-bf09-c79ce1a35d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gene tokenization data...\n",
      "Loaded 25426 gene tokens\n",
      "Loading gene median expression data...\n",
      "Loaded 25424 gene median expression values\n",
      "Loading AnnData from /nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad...\n",
      "Loaded AnnData with shape (66, 19393)\n",
      "Checking for and/or calculating total counts per cell...\n",
      "Tokenizing and ranking genes...\n",
      "Processed 66 cells\n",
      "Creating Hugging Face dataset...\n",
      "Dataset has 66 examples\n",
      "Formatting cell features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7507b57856a640a7b673669acdfc3a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed dataset to /nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb3b051f5564de18614a478552acc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading gene tokenization data...\")\n",
    "gene_token_dict, gene_keys, genelist_dict = load_gene_tokenization(token_path)\n",
    "print(f\"Loaded {len(gene_token_dict)} gene tokens\")\n",
    "\n",
    "print(\"Loading gene median expression data...\")\n",
    "gene_median_dict = load_gene_median_dict(median_path)\n",
    "print(f\"Loaded {len(gene_median_dict)} gene median expression values\")\n",
    "\n",
    "if map_names:\n",
    "    print(\"Loading gene name mapping data...\")\n",
    "    gene_names = load_gene_names(gene_names)\n",
    "    print(f\"Loaded {len(gene_names)} gene name mappings\")\n",
    "\n",
    "# Load and pre-process data\n",
    "print(f\"Loading AnnData from {input_path}...\")\n",
    "adata = sc.read_h5ad(input_path)\n",
    "print(f\"Loaded AnnData with shape {adata.shape}\")\n",
    "\n",
    "if map_names:\n",
    "    print(\"Mapping gene names to Ensembl IDs...\")\n",
    "    adata = map_gene_names(adata, gene_id, gene_name_column, gene_names)\n",
    "\n",
    "if not layer == 'X':\n",
    "    print(f\"Using layer '{layer}' for expression data...\")\n",
    "    adata.X = adata.layers[layer]\n",
    "    \n",
    "print(\"Checking for and/or calculating total counts per cell...\")\n",
    "adata = check_counts_column(adata, counts_column)\n",
    "\n",
    "# Tokenize and rank genes\n",
    "print(\"Tokenizing and ranking genes...\")\n",
    "tokenized_cells, cell_metadata = tokenize_anndata(\n",
    "    adata, genelist_dict, gene_median_dict,\n",
    "    target_sum=target_sum, gene_id=gene_id, counts_column=counts_column\n",
    ")\n",
    "print(f\"Processed {len(tokenized_cells)} cells\")\n",
    "\n",
    "# Create Hugging Face dataset\n",
    "print(\"Creating Hugging Face dataset...\")\n",
    "dataset_dict = {\n",
    "    \"input_ids\": tokenized_cells,\n",
    "    **cell_metadata\n",
    "}\n",
    "output_dataset = Dataset.from_dict(dataset_dict)\n",
    "print(f\"Dataset has {len(output_dataset)} examples\")\n",
    "\n",
    "# Format cell features\n",
    "print(\"Formatting cell features...\")\n",
    "dataset = output_dataset.map(format_cell_features, num_proc=n_proc)\n",
    "\n",
    "# Save dataset\n",
    "print(f\"Saving processed dataset to {output_path}...\")\n",
    "save_hf_dataset(dataset, output_path, overwrite=True)\n",
    "print(\"Processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22367c34-f463-4215-bd95-06d626b3f740",
   "metadata": {},
   "source": [
    "## Embedding Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272851fc-37f4-47af-ae17-076427806d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import anndata as an\n",
    "import scanpy as sc\n",
    "from datasets import Dataset, load_from_disk\n",
    "sys.path.append('/home/jpic/geneformer_dev/scripts')\n",
    "import geneformer_utils as gtu\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd7633c-b331-48d6-957a-3ae5d6c860d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/jpic/geneformer_dev/scripts')\n",
    "import geneformer_utils as gtu\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220f359a-25e6-478f-946a-74a9cae5a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\n",
      "Loading model from '/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Loading dataset from '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.dataset' (up to None cells)...\n",
      "Dataset loaded successfully!\n",
      "Extracting embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bc976ac05d4c2c9578d6635f42ce37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings extracted successfully!\n",
      "Writing results to '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic_GF_embeddings'...\n",
      "Output file written successfully!\n"
     ]
    }
   ],
   "source": [
    "dataset_path = arg_out\n",
    "model_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer-12L-30M/\"\n",
    "outpath = arg_out2\n",
    "num_cells = None # all cells, useful for testing \n",
    "\n",
    "print(model_path)\n",
    "\n",
    "print(f\"Loading model from '{model_path}'...\")\n",
    "model = gtu.load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "print(f\"Loading dataset from '{dataset_path}' (up to {num_cells} cells)...\")\n",
    "try:\n",
    "    df = gtu.load_data_as_dataframe(dataset_path, num_cells=num_cells)\n",
    "    data = Dataset.from_pandas(df)\n",
    "    df = df.drop(columns='input_ids')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Dataset file not found at '{dataset_path}'\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:  # Catching other potential errors\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    sys.exit(1)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "\n",
    "print(\"Extracting embeddings...\")\n",
    "embs = gtu.extract_embedding_in_mem(model, data)\n",
    "adata = gtu.embedding_to_adata(embs)\n",
    "adata.obs = df.astype(str).reset_index().copy()\n",
    "print(\"Embeddings extracted successfully!\")\n",
    "\n",
    "print(f\"Writing results to '{outpath}'...\")\n",
    "try:\n",
    "    adata.write(outpath)\n",
    "except Exception as e:\n",
    "    print(f\"Error writing output file: {e}\")\n",
    "    sys.exit(1)\n",
    "print(\"Output file written successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391eeed-a91b-4834-8ff4-f662ebb786ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512a85f2-16c2-4dd4-8a82-86dbbea68bbb",
   "metadata": {},
   "source": [
    "## Helper Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9825e8cd-484e-4a44-b5b2-50f3752caf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from to_geneformer.py\n",
    "def check_counts_column(adata, counts_column):\n",
    "    \"\"\"Checks for and calculates a total counts column in AnnData.\n",
    "\n",
    "    This function examines the AnnData object's observation (`obs`) columns for the specified \n",
    "    `counts_column`. If it doesn't exist, the function calculates the sum of each row (cell) \n",
    "    across all features in the data matrix (`X`) and stores it as a new column in `obs`.\n",
    "\n",
    "    Args:\n",
    "        adata: An AnnData object containing the data to be analyzed.\n",
    "        counts_column: A string representing the desired name for the total counts column.\n",
    "\n",
    "    Returns:\n",
    "        adata: The modified AnnData object, now with the `counts_column` present (either \n",
    "               pre-existing or newly calculated).\n",
    "    \"\"\"\n",
    "    obs_columns = adata.obs.columns\n",
    "    \n",
    "    if counts_column in obs_columns:\n",
    "        return adata\n",
    "    else:\n",
    "        adata.obs[counts_column] = adata.X.sum(axis=1)\n",
    "        return adata\n",
    "    \n",
    "    \n",
    "def map_gene_names(adata, gene_id, gene_name_column, gene_names):\n",
    "    \"\"\"A function mapping gene names to gene ids \"\"\"\n",
    "    var_columns = adata.var.columns\n",
    "    \n",
    "    if gene_id in var_columns:\n",
    "        return adata\n",
    "    else:\n",
    "        adata.var[gene_id] = adata.var[gene_name_column].map(gene_names)\n",
    "        return adata\n",
    "    \n",
    "    \n",
    "def load_gene_names(gene_names_file):\n",
    "    \"\"\"\n",
    "    Loads a gene median dictionary from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        gene_names_file (str): Path to the pickle file containing the gene names dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping gene names to IDs\n",
    "    \"\"\"\n",
    "\n",
    "    with open(gene_names_file, \"rb\") as f:\n",
    "        gene_names_dict = pickle.load(f)\n",
    "\n",
    "    return gene_names_dict\n",
    "\n",
    "\n",
    "def load_gene_median_dict(gene_median_file):\n",
    "    \"\"\"\n",
    "    Loads a gene median dictionary from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        gene_median_file (str): Path to the pickle file containing the gene median dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping gene IDs to their median expression values.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(gene_median_file, \"rb\") as f:\n",
    "        gene_median_dict = pickle.load(f)\n",
    "\n",
    "    return gene_median_dict\n",
    "\n",
    "\n",
    "def load_gene_tokenization(token_dictionary_file):\n",
    "    \"\"\"\n",
    "    Loads gene tokenization data from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        token_dictionary_file (str): Path to the pickle file containing the gene-token dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: Gene-token dictionary (Ensembl ID: token).\n",
    "        list: List of all gene keys (Ensembl IDs).\n",
    "        dict: Dictionary mapping gene keys to True (used for selecting genes later).\n",
    "    \"\"\"\n",
    "\n",
    "    with open(token_dictionary_file, \"rb\") as f:\n",
    "        gene_token_dict = pickle.load(f)\n",
    "\n",
    "    gene_keys = list(gene_token_dict.keys())\n",
    "\n",
    "    # Optimization: Pre-allocate the list for slight performance improvement\n",
    "    genelist_dict = dict.fromkeys(gene_keys, True)\n",
    "\n",
    "    return gene_token_dict, gene_keys, genelist_dict\n",
    "\n",
    "\n",
    "def rank_genes(gene_vector, gene_tokens):\n",
    "    \"\"\"Ranks genes based on expression values in descending order.\n",
    "\n",
    "    Args:\n",
    "        gene_vector (numpy.ndarray): Array of gene expression values.\n",
    "        gene_tokens (numpy.ndarray): Array of corresponding gene tokens.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of gene tokens sorted by descending expression value.\n",
    "    \"\"\"\n",
    "    return gene_tokens[np.argsort(-gene_vector)]\n",
    "\n",
    "\n",
    "def normalize_counts(adata_chunk,  counts_column='n_counts', target_sum=10000):\n",
    "    \"\"\"Normalizes gene expression counts within a chunk of AnnData.\n",
    "\n",
    "    Args:\n",
    "        adata_chunk (AnnData): A chunk of the AnnData object containing gene expression data.\n",
    "        counts_column (str): Name of the column in `adata_chunk.obs` containing the total counts per cell.\n",
    "        target_sum (float): The desired total count per cell after normalization.\n",
    "        norm_factor_vector (numpy.ndarray): An array of normalization factors for each gene.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: A sparse matrix containing the normalized gene expression counts.\n",
    "\n",
    "    This function performs the following steps:\n",
    "        1. Extracts the total counts per cell from the specified column (`counts_column`).\n",
    "        2. Normalizes the gene expression matrix (`adata_chunk.X`) by dividing by the total counts \n",
    "           and multiplying by the `target_sum`.\n",
    "        3. Further adjusts the normalized values by dividing by the gene-specific normalization \n",
    "           factors (`norm_factor_vector`).\n",
    "        4. Returns the normalized expression matrix as a sparse CSR matrix for efficient storage \n",
    "           and computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_counts = adata_chunk.obs[counts_column].values[:, None]  # Cell counts as column vector\n",
    "    X_norm = adata_chunk.X / n_counts * target_sum / norm_factor_vector\n",
    "    return sp.csr_matrix(X_norm)  # Efficient sparse representation\n",
    "\n",
    "\n",
    "def tokenize_anndata(adata, genelist_dict, gene_median_dict, \n",
    "                     chunk_size=100000, target_sum=10000, \n",
    "                     counts_column='n_counts', gene_id=\"ensembl_id\"):\n",
    "    \"\"\"\n",
    "    Tokenizes and ranks genes within an AnnData object, optimizing for memory efficiency.\n",
    "\n",
    "    This function processes gene expression data in chunks, applies normalization, and ranks genes\n",
    "    for each cell based on their expression levels. The resulting tokenized and ranked gene\n",
    "    representations, along with cell metadata, are returned.\n",
    "\n",
    "    Args:\n",
    "        adata (AnnData): The AnnData object containing gene expression data.\n",
    "        genelist_dict (dict): Dictionary mapping gene IDs to boolean values indicating relevance.\n",
    "        gene_median_dict (dict): Dictionary mapping gene IDs to their median expression values.\n",
    "        chunk_size (int, optional): Number of cells to process in each chunk (default: 1000).\n",
    "        target_sum (int, optional): Target sum for count normalization (default: 10000).\n",
    "        counts_column (str, optional): The column in `adata.obs` containing cell counts (default: 'n_counts').\n",
    "        gene_id (str, optional): The column in `adata.var` containing gene IDs (default: 'ensembl_id').\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - list: List of tokenized and ranked gene lists for each cell.\n",
    "            - dict: Dictionary containing cell metadata (keys are metadata column names).\n",
    "    \"\"\"\n",
    "    # Filter relevant miRNAs\n",
    "    coding_miRNA_mask = np.array([genelist_dict.get(i, False) for i in adata.var[gene_id]])\n",
    "    coding_miRNA_loc = np.where(coding_miRNA_mask)[0]\n",
    "\n",
    "    # Extract miRNA information\n",
    "    coding_miRNA_ids = adata.var[gene_id].iloc[coding_miRNA_loc]\n",
    "    norm_factor_vector = np.array([gene_median_dict[i] for i in coding_miRNA_ids])\n",
    "    coding_miRNA_tokens = np.array([gene_token_dict[i] for i in coding_miRNA_ids])\n",
    "\n",
    "    tokenized_cells = []\n",
    "    file_cell_metadata = {k: [] for k in adata.obs.columns}  # Initialize metadata dict\n",
    "\n",
    "    # Process in chunks for memory efficiency\n",
    "    for chunk_start in range(0, adata.shape[0], chunk_size):\n",
    "        chunk_end = chunk_start + chunk_size\n",
    "        adata_chunk = adata[chunk_start:chunk_end, coding_miRNA_loc]\n",
    "        \n",
    "        # Normalize counts (could be replaced with the untested function above)\n",
    "        n_counts = adata_chunk.obs[counts_column].values[:, None]\n",
    "        X_norm = adata_chunk.X / n_counts * target_sum / norm_factor_vector\n",
    "        X_norm = sp.csr_matrix(X_norm)  \n",
    "\n",
    "        # Tokenize and rank genes for each cell in chunk\n",
    "        for i in range(X_norm.shape[0]):\n",
    "            ranks = rank_genes(X_norm[i].data, coding_miRNA_tokens[X_norm[i].indices])\n",
    "            ranks = list(ranks[~np.isnan(ranks)].astype(int))\n",
    "\n",
    "            tokenized_cells.append(ranks)\n",
    "\n",
    "        # Update metadata\n",
    "        for k in adata.obs.columns:\n",
    "            file_cell_metadata[k].extend(adata_chunk.obs[k].astype(str).tolist())\n",
    "\n",
    "    return tokenized_cells, file_cell_metadata\n",
    "\n",
    "\n",
    "def format_cell_features(example):\n",
    "    \"\"\"\n",
    "    Truncates gene tokens (`input_ids`) to `model_size` and adds a `length` feature.\n",
    "\n",
    "    Args:\n",
    "        example (dict): Cell data with `input_ids` (list of gene tokens).\n",
    "\n",
    "    Returns:\n",
    "        dict: Modified cell data with truncated `input_ids` and added `length`.\n",
    "    \"\"\"\n",
    "    example[\"input_ids\"] = example[\"input_ids\"][0:model_size] \n",
    "    example[\"length\"] = len(example[\"input_ids\"]) \n",
    "    return example\n",
    "\n",
    "\n",
    "def save_hf_dataset(dataset: Dataset, output_path: str, overwrite=True):\n",
    "    \"\"\"\n",
    "    Saves a Hugging Face Dataset to disk at a specified file path.\n",
    "\n",
    "    This function serializes a Hugging Face `Dataset` object and saves it to disk in the Arrow format.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): The Hugging Face `Dataset` object to be saved.\n",
    "        output_path (str): The full file path (including the filename) where the dataset will be saved. \n",
    "        overwrite (bool, optional): If `True`, an existing dataset at `output_path` will be overwritten. \n",
    "                                   If `False` and the file exists, a `FileExistsError` is raised (default: True).\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If `dataset` is not a Hugging Face `Dataset` instance.\n",
    "        FileExistsError: If `output_path` points to an existing file and `overwrite` is False.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise TypeError(\"The provided dataset is not a Hugging Face Dataset.\")\n",
    "\n",
    "    if os.path.exists(output_path) and not overwrite:\n",
    "        raise FileExistsError(\n",
    "            f\"Dataset '{output_path}' already exists. Set `overwrite=True` to overwrite.\"\n",
    "        )\n",
    "    dataset.save_to_disk(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7545ac-90db-4ae6-b000-e2266ec2833a",
   "metadata": {},
   "source": [
    "## Check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07bfc48-38e1-41a6-a960-ecf247cd38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/anndata/_core/aligned_df.py:67: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66 × 512\n",
       "    obs: 'index', 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control', 'order', 'replicate', 'batch', 'length'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(arg_out2)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a36552a-239c-425c-be81-ad2e0c4d16a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D507</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D508</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D509</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D510</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D511</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [D0, D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, D11, D12, D13, D14, D15, D16, D17, D18, D19, D20, D21, D22, D23, D24, D25, D26, D27, D28, D29, D30, D31, D32, D33, D34, D35, D36, D37, D38, D39, D40, D41, D42, D43, D44, D45, D46, D47, D48, D49, D50, D51, D52, D53, D54, D55, D56, D57, D58, D59, D60, D61, D62, D63, D64, D65, D66, D67, D68, D69, D70, D71, D72, D73, D74, D75, D76, D77, D78, D79, D80, D81, D82, D83, D84, D85, D86, D87, D88, D89, D90, D91, D92, D93, D94, D95, D96, D97, D98, D99, ...]\n",
       "\n",
       "[512 rows x 0 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3381bd-f80a-4215-a538-05046a1fda31",
   "metadata": {},
   "source": [
    "# JPIC Data Engineering\n",
    "\n",
    "In this file Joshua changes a file made by cooper to standardize the time point and replicate naming from files made by cooper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78302459-b880-4877-bafa-2e06325111f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import anndata as an\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2396ebef-2bbb-472e-be75-120887e17553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "coopers_data_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data.h5ad\"\n",
    "ad = an.read(coopers_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452e19f4-2fa9-4b97-9d31-f51a62f23e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Source</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Score</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Frame</th>\n",
       "      <th>...</th>\n",
       "      <th>transcript_biotype</th>\n",
       "      <th>tag</th>\n",
       "      <th>ccds_id</th>\n",
       "      <th>exon_number</th>\n",
       "      <th>exon_id</th>\n",
       "      <th>exon_version</th>\n",
       "      <th>protein_id</th>\n",
       "      <th>protein_version</th>\n",
       "      <th>transcript_support_level</th>\n",
       "      <th>ensembl_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1BG</th>\n",
       "      <td>ENSG00000121410</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>19</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>58345177.0</td>\n",
       "      <td>58353492.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000121410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CF</th>\n",
       "      <td>ENSG00000148584</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>10</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>50799408.0</td>\n",
       "      <td>50885675.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000148584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M</th>\n",
       "      <td>ENSG00000175899</td>\n",
       "      <td>13826.0</td>\n",
       "      <td>12</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>9067663.0</td>\n",
       "      <td>9116229.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000175899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ML1</th>\n",
       "      <td>ENSG00000166535</td>\n",
       "      <td>11812.0</td>\n",
       "      <td>12</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>8822620.0</td>\n",
       "      <td>8887001.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000166535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3GALT2</th>\n",
       "      <td>ENSG00000184389</td>\n",
       "      <td>15327.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>33306765.0</td>\n",
       "      <td>33321098.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000184389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYG11A</th>\n",
       "      <td>ENSG00000203995</td>\n",
       "      <td>17515.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>52842510.0</td>\n",
       "      <td>52894998.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000203995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYG11B</th>\n",
       "      <td>ENSG00000162378</td>\n",
       "      <td>10655.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>52726452.0</td>\n",
       "      <td>52827336.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000162378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZYX</th>\n",
       "      <td>ENSG00000159840</td>\n",
       "      <td>10336.0</td>\n",
       "      <td>7</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>143381294.0</td>\n",
       "      <td>143391111.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000159840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZEF1</th>\n",
       "      <td>ENSG00000074755</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>17</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>4004444.0</td>\n",
       "      <td>4143030.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000074755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZ3</th>\n",
       "      <td>ENSG00000036549</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ensembl_havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>77562415.0</td>\n",
       "      <td>77683419.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENSG00000036549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19393 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   gene_id  token_id Chromosome          Source Feature  \\\n",
       "gene_name                                                                 \n",
       "A1BG       ENSG00000121410    5150.0         19  ensembl_havana    gene   \n",
       "A1CF       ENSG00000148584    9064.0         10  ensembl_havana    gene   \n",
       "A2M        ENSG00000175899   13826.0         12  ensembl_havana    gene   \n",
       "A2ML1      ENSG00000166535   11812.0         12  ensembl_havana    gene   \n",
       "A3GALT2    ENSG00000184389   15327.0          1  ensembl_havana    gene   \n",
       "...                    ...       ...        ...             ...     ...   \n",
       "ZYG11A     ENSG00000203995   17515.0          1  ensembl_havana    gene   \n",
       "ZYG11B     ENSG00000162378   10655.0          1  ensembl_havana    gene   \n",
       "ZYX        ENSG00000159840   10336.0          7  ensembl_havana    gene   \n",
       "ZZEF1      ENSG00000074755    1277.0         17  ensembl_havana    gene   \n",
       "ZZZ3       ENSG00000036549     533.0          1  ensembl_havana    gene   \n",
       "\n",
       "                 Start          End Score Strand Frame  ...  \\\n",
       "gene_name                                               ...   \n",
       "A1BG        58345177.0   58353492.0     .      -     .  ...   \n",
       "A1CF        50799408.0   50885675.0     .      -     .  ...   \n",
       "A2M          9067663.0    9116229.0     .      -     .  ...   \n",
       "A2ML1        8822620.0    8887001.0     .      +     .  ...   \n",
       "A3GALT2     33306765.0   33321098.0     .      -     .  ...   \n",
       "...                ...          ...   ...    ...   ...  ...   \n",
       "ZYG11A      52842510.0   52894998.0     .      +     .  ...   \n",
       "ZYG11B      52726452.0   52827336.0     .      +     .  ...   \n",
       "ZYX        143381294.0  143391111.0     .      +     .  ...   \n",
       "ZZEF1        4004444.0    4143030.0     .      -     .  ...   \n",
       "ZZZ3        77562415.0   77683419.0     .      -     .  ...   \n",
       "\n",
       "           transcript_biotype tag ccds_id  exon_number  exon_id  exon_version  \\\n",
       "gene_name                                                                       \n",
       "A1BG                      NaN NaN     NaN          NaN      NaN           NaN   \n",
       "A1CF                      NaN NaN     NaN          NaN      NaN           NaN   \n",
       "A2M                       NaN NaN     NaN          NaN      NaN           NaN   \n",
       "A2ML1                     NaN NaN     NaN          NaN      NaN           NaN   \n",
       "A3GALT2                   NaN NaN     NaN          NaN      NaN           NaN   \n",
       "...                       ...  ..     ...          ...      ...           ...   \n",
       "ZYG11A                    NaN NaN     NaN          NaN      NaN           NaN   \n",
       "ZYG11B                    NaN NaN     NaN          NaN      NaN           NaN   \n",
       "ZYX                       NaN NaN     NaN          NaN      NaN           NaN   \n",
       "ZZEF1                     NaN NaN     NaN          NaN      NaN           NaN   \n",
       "ZZZ3                      NaN NaN     NaN          NaN      NaN           NaN   \n",
       "\n",
       "           protein_id  protein_version  transcript_support_level  \\\n",
       "gene_name                                                          \n",
       "A1BG              NaN              NaN                       NaN   \n",
       "A1CF              NaN              NaN                       NaN   \n",
       "A2M               NaN              NaN                       NaN   \n",
       "A2ML1             NaN              NaN                       NaN   \n",
       "A3GALT2           NaN              NaN                       NaN   \n",
       "...               ...              ...                       ...   \n",
       "ZYG11A            NaN              NaN                       NaN   \n",
       "ZYG11B            NaN              NaN                       NaN   \n",
       "ZYX               NaN              NaN                       NaN   \n",
       "ZZEF1             NaN              NaN                       NaN   \n",
       "ZZZ3              NaN              NaN                       NaN   \n",
       "\n",
       "                ensembl_id  \n",
       "gene_name                   \n",
       "A1BG       ENSG00000121410  \n",
       "A1CF       ENSG00000148584  \n",
       "A2M        ENSG00000175899  \n",
       "A2ML1      ENSG00000166535  \n",
       "A3GALT2    ENSG00000184389  \n",
       "...                    ...  \n",
       "ZYG11A     ENSG00000203995  \n",
       "ZYG11B     ENSG00000162378  \n",
       "ZYX        ENSG00000159840  \n",
       "ZZEF1      ENSG00000074755  \n",
       "ZZZ3       ENSG00000036549  \n",
       "\n",
       "[19393 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceab5f32-aeb0-426a-93c2-94cf7539b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timepoint_replicate_2015(data_id):\n",
    "    match = re.match(r\"S(\\d+)([ab])\", data_id)\n",
    "    if match:\n",
    "        time = int(match.group(1))\n",
    "        replicate = 1 if match.group(2) == 'a' else 2\n",
    "        return time, replicate\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def extract_timepoint_replicate_2018(data_id):\n",
    "    match = re.match(r\"(\\d+)_T(\\d+)R(\\d+)\", data_id)\n",
    "    if match:\n",
    "        return int(match.group(2)), int(match.group(3))\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d076ec84-f1f7-4191-a1c4-3126d5300c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adDs5 = ad[ad.obs['dataset'] == 'chen_2015']\n",
    "adDs8 = ad[ad.obs['dataset'] == 'liu_2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e92d00-9f20-4c2e-a93a-c8422e252e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 48 × 19393\n",
       "    obs: 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control', 'order', 'replicate'\n",
       "    var: 'gene_id', 'token_id', 'Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'gene_version', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'tag', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version', 'transcript_support_level', 'ensembl_id'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepoint_replicate = adDs8.obs.index.to_series().apply(extract_timepoint_replicate_2018)\n",
    "timepoint_replicate_df = timepoint_replicate.apply(pd.Series)\n",
    "timepoint_replicate_df.columns = ['order', 'replicate']\n",
    "\n",
    "# Add the new columns to the AnnData object\n",
    "adDs8.obs = adDs8.obs.join(timepoint_replicate_df)\n",
    "adDs8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11db5de0-d6ec-4372-b188-114466d7b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 18 × 19393\n",
       "    obs: 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control', 'order', 'replicate'\n",
       "    var: 'gene_id', 'token_id', 'Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'gene_version', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'tag', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version', 'transcript_support_level', 'ensembl_id'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepoint_replicate = adDs5.obs.index.to_series().apply(extract_timepoint_replicate_2015)\n",
    "timepoint_replicate_df = timepoint_replicate.apply(pd.Series)\n",
    "timepoint_replicate_df.columns = ['order', 'replicate']\n",
    "\n",
    "# Add the new columns to the AnnData object\n",
    "adDs5.obs = adDs5.obs.join(timepoint_replicate_df)\n",
    "adDs5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a66e71-94c5-47a7-95f3-52179fdc2022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>hour</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>control</th>\n",
       "      <th>order</th>\n",
       "      <th>replicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7901832</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8113329</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9831046</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10123271</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S3a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10490839</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S3b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10713844</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S4a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9183324</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S4b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9401913</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S5a</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9655719</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S5b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9863515</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S6a</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8237619</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S6b</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8416384</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S7a</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9020122</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S7b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9245357</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S8a</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7793726</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S8b</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7966395</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S9a</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9292719</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S9b</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9506858</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset sample_id  timepoint  hour  n_counts  control  order  \\\n",
       "data_id                                                                   \n",
       "S1a      chen_2015       S1a        0.0   0.0   7901832     True      1   \n",
       "S1b      chen_2015       S1b        0.0   0.0   8113329     True      1   \n",
       "S2a      chen_2015       S2a        0.0   0.0   9831046    False      2   \n",
       "S2b      chen_2015       S2b        0.0   0.0  10123271    False      2   \n",
       "S3a      chen_2015       S3a        1.0   8.0  10490839    False      3   \n",
       "S3b      chen_2015       S3b        1.0   8.0  10713844    False      3   \n",
       "S4a      chen_2015       S4a        2.0  16.0   9183324    False      4   \n",
       "S4b      chen_2015       S4b        2.0  16.0   9401913    False      4   \n",
       "S5a      chen_2015       S5a        3.0  24.0   9655719    False      5   \n",
       "S5b      chen_2015       S5b        3.0  24.0   9863515    False      5   \n",
       "S6a      chen_2015       S6a        4.0  32.0   8237619    False      6   \n",
       "S6b      chen_2015       S6b        4.0  32.0   8416384    False      6   \n",
       "S7a      chen_2015       S7a        5.0  40.0   9020122    False      7   \n",
       "S7b      chen_2015       S7b        5.0  40.0   9245357    False      7   \n",
       "S8a      chen_2015       S8a        6.0  48.0   7793726    False      8   \n",
       "S8b      chen_2015       S8b        6.0  48.0   7966395    False      8   \n",
       "S9a      chen_2015       S9a        7.0  56.0   9292719    False      9   \n",
       "S9b      chen_2015       S9b        7.0  56.0   9506858    False      9   \n",
       "\n",
       "         replicate  \n",
       "data_id             \n",
       "S1a              1  \n",
       "S1b              2  \n",
       "S2a              1  \n",
       "S2b              2  \n",
       "S3a              1  \n",
       "S3b              2  \n",
       "S4a              1  \n",
       "S4b              2  \n",
       "S5a              1  \n",
       "S5b              2  \n",
       "S6a              1  \n",
       "S6b              2  \n",
       "S7a              1  \n",
       "S7b              2  \n",
       "S8a              1  \n",
       "S8b              2  \n",
       "S9a              1  \n",
       "S9b              2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adDs5.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff2a5a9-f4f7-46f4-9902-2c4b77ed2a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>hour</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>control</th>\n",
       "      <th>order</th>\n",
       "      <th>replicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63246_T0R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>11940999</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63252_T1R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63252</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18063509</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63249_T2R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11031474</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63261_T3R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16761043</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63258_T4R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8244802</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63255_T5R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63255</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10615057</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63270_T6R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16486670</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63267_T7R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63267</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10127547</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63264_T8R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63264</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11231585</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63279_T9R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>10781978</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63276_T10R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63276</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>13893356</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63273_T11R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63273</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10505739</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63288_T12R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12022778</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63285_T13R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12357417</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63282_T14R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63282</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>8599448</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63291_T15R1</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>10504361</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63247_T0R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>11789487</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63253_T1R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63253</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13420533</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63250_T2R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63250</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12497728</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63262_T3R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11340074</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63259_T4R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63259</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9023684</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63256_T5R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63256</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13012866</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63271_T6R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14442928</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63268_T7R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63268</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13032408</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63265_T8R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14518072</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63280_T9R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13542791</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63277_T10R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15572054</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63274_T11R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63274</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10752508</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63289_T12R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>11955022</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63286_T13R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10311196</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63283_T14R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63283</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5099724</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63292_T15R2</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>12797307</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63248_T0R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>13419966</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63254_T1R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8799446</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63251_T2R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63251</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11545564</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63263_T3R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12865329</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63260_T4R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63260</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8775872</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63257_T5R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63257</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10098736</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63272_T6R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>14571928</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63269_T7R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63269</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>11792348</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63266_T8R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63266</td>\n",
       "      <td>3.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>14019844</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63281_T9R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12211725</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63278_T10R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>13437658</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63275_T11R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13515971</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63290_T12R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9522866</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63287_T13R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12370157</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63284_T14R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63284</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10970735</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63293_T15R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13244720</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset sample_id  timepoint   hour  n_counts  control  order  \\\n",
       "data_id                                                                       \n",
       "63246_T0R1   liu_2018     63246        1.0  -48.0  11940999     True      0   \n",
       "63252_T1R1   liu_2018     63252        2.0    0.0  18063509    False      1   \n",
       "63249_T2R1   liu_2018     63249        3.0    8.0  11031474    False      2   \n",
       "63261_T3R1   liu_2018     63261        1.0   16.0  16761043    False      3   \n",
       "63258_T4R1   liu_2018     63258        2.0   24.0   8244802    False      4   \n",
       "63255_T5R1   liu_2018     63255        3.0   32.0  10615057    False      5   \n",
       "63270_T6R1   liu_2018     63270        1.0   40.0  16486670    False      6   \n",
       "63267_T7R1   liu_2018     63267        2.0   48.0  10127547    False      7   \n",
       "63264_T8R1   liu_2018     63264        3.0   56.0  11231585    False      8   \n",
       "63279_T9R1   liu_2018     63279        1.0   64.0  10781978    False      9   \n",
       "63276_T10R1  liu_2018     63276        2.0   72.0  13893356    False     10   \n",
       "63273_T11R1  liu_2018     63273        3.0   80.0  10505739    False     11   \n",
       "63288_T12R1  liu_2018     63288        1.0   88.0  12022778    False     12   \n",
       "63285_T13R1  liu_2018     63285        2.0   96.0  12357417    False     13   \n",
       "63282_T14R1  liu_2018     63282        3.0  104.0   8599448    False     14   \n",
       "63291_T15R1  liu_2018     63291        1.0  112.0  10504361    False     15   \n",
       "63247_T0R2   liu_2018     63247        1.0  -48.0  11789487     True      0   \n",
       "63253_T1R2   liu_2018     63253        2.0    0.0  13420533    False      1   \n",
       "63250_T2R2   liu_2018     63250        3.0    8.0  12497728    False      2   \n",
       "63262_T3R2   liu_2018     63262        1.0   16.0  11340074    False      3   \n",
       "63259_T4R2   liu_2018     63259        2.0   24.0   9023684    False      4   \n",
       "63256_T5R2   liu_2018     63256        3.0   32.0  13012866    False      5   \n",
       "63271_T6R2   liu_2018     63271        1.0   40.0  14442928    False      6   \n",
       "63268_T7R2   liu_2018     63268        2.0   48.0  13032408    False      7   \n",
       "63265_T8R2   liu_2018     63265        3.0   56.0  14518072    False      8   \n",
       "63280_T9R2   liu_2018     63280        1.0   64.0  13542791    False      9   \n",
       "63277_T10R2  liu_2018     63277        2.0   72.0  15572054    False     10   \n",
       "63274_T11R2  liu_2018     63274        3.0   80.0  10752508    False     11   \n",
       "63289_T12R2  liu_2018     63289        1.0   88.0  11955022    False     12   \n",
       "63286_T13R2  liu_2018     63286        2.0   96.0  10311196    False     13   \n",
       "63283_T14R2  liu_2018     63283        3.0  104.0   5099724    False     14   \n",
       "63292_T15R2  liu_2018     63292        1.0  112.0  12797307    False     15   \n",
       "63248_T0R3   liu_2018     63248        1.0  -48.0  13419966     True      0   \n",
       "63254_T1R3   liu_2018     63254        2.0    0.0   8799446    False      1   \n",
       "63251_T2R3   liu_2018     63251        3.0    8.0  11545564    False      2   \n",
       "63263_T3R3   liu_2018     63263        1.0   16.0  12865329    False      3   \n",
       "63260_T4R3   liu_2018     63260        2.0   24.0   8775872    False      4   \n",
       "63257_T5R3   liu_2018     63257        3.0   32.0  10098736    False      5   \n",
       "63272_T6R3   liu_2018     63272        1.0   40.0  14571928    False      6   \n",
       "63269_T7R3   liu_2018     63269        2.0   48.0  11792348    False      7   \n",
       "63266_T8R3   liu_2018     63266        3.0   56.0  14019844    False      8   \n",
       "63281_T9R3   liu_2018     63281        1.0   64.0  12211725    False      9   \n",
       "63278_T10R3  liu_2018     63278        2.0   72.0  13437658    False     10   \n",
       "63275_T11R3  liu_2018     63275        3.0   80.0  13515971    False     11   \n",
       "63290_T12R3  liu_2018     63290        1.0   88.0   9522866    False     12   \n",
       "63287_T13R3  liu_2018     63287        2.0   96.0  12370157    False     13   \n",
       "63284_T14R3  liu_2018     63284        3.0  104.0  10970735    False     14   \n",
       "63293_T15R3  liu_2018     63293        1.0  112.0  13244720    False     15   \n",
       "\n",
       "             replicate  \n",
       "data_id                 \n",
       "63246_T0R1           1  \n",
       "63252_T1R1           1  \n",
       "63249_T2R1           1  \n",
       "63261_T3R1           1  \n",
       "63258_T4R1           1  \n",
       "63255_T5R1           1  \n",
       "63270_T6R1           1  \n",
       "63267_T7R1           1  \n",
       "63264_T8R1           1  \n",
       "63279_T9R1           1  \n",
       "63276_T10R1          1  \n",
       "63273_T11R1          1  \n",
       "63288_T12R1          1  \n",
       "63285_T13R1          1  \n",
       "63282_T14R1          1  \n",
       "63291_T15R1          1  \n",
       "63247_T0R2           2  \n",
       "63253_T1R2           2  \n",
       "63250_T2R2           2  \n",
       "63262_T3R2           2  \n",
       "63259_T4R2           2  \n",
       "63256_T5R2           2  \n",
       "63271_T6R2           2  \n",
       "63268_T7R2           2  \n",
       "63265_T8R2           2  \n",
       "63280_T9R2           2  \n",
       "63277_T10R2          2  \n",
       "63274_T11R2          2  \n",
       "63289_T12R2          2  \n",
       "63286_T13R2          2  \n",
       "63283_T14R2          2  \n",
       "63292_T15R2          2  \n",
       "63248_T0R3           3  \n",
       "63254_T1R3           3  \n",
       "63251_T2R3           3  \n",
       "63263_T3R3           3  \n",
       "63260_T4R3           3  \n",
       "63257_T5R3           3  \n",
       "63272_T6R3           3  \n",
       "63269_T7R3           3  \n",
       "63266_T8R3           3  \n",
       "63281_T9R3           3  \n",
       "63278_T10R3          3  \n",
       "63275_T11R3          3  \n",
       "63290_T12R3          3  \n",
       "63287_T13R3          3  \n",
       "63284_T14R3          3  \n",
       "63293_T15R3          3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adDs8.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e71f347-61b5-4abf-8617-0ca3c8fb5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3228990/494883074.py:1: FutureWarning: Use anndata.concat instead of AnnData.concatenate, AnnData.concatenate is deprecated and will be removed in the future. See the tutorial for concat at: https://anndata.readthedocs.io/en/latest/concatenation.html\n",
      "  adDs_combined = adDs5.concatenate(adDs8, join='outer', index_unique=None)\n"
     ]
    }
   ],
   "source": [
    "adDs_combined = adDs5.concatenate(adDs8, join='outer', index_unique=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12312dbe-01e5-40ff-87f9-a89040f1f67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>hour</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>control</th>\n",
       "      <th>order</th>\n",
       "      <th>replicate</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7901832</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8113329</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9831046</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2b</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10123271</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3a</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S3a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10490839</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63275_T11R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13515971</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63290_T12R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9522866</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63287_T13R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12370157</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63284_T14R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63284</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10970735</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63293_T15R3</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13244720</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset sample_id  timepoint   hour  n_counts  control  order  \\\n",
       "data_id                                                                        \n",
       "S1a          chen_2015       S1a        0.0    0.0   7901832     True      1   \n",
       "S1b          chen_2015       S1b        0.0    0.0   8113329     True      1   \n",
       "S2a          chen_2015       S2a        0.0    0.0   9831046    False      2   \n",
       "S2b          chen_2015       S2b        0.0    0.0  10123271    False      2   \n",
       "S3a          chen_2015       S3a        1.0    8.0  10490839    False      3   \n",
       "...                ...       ...        ...    ...       ...      ...    ...   \n",
       "63275_T11R3   liu_2018     63275        3.0   80.0  13515971    False     11   \n",
       "63290_T12R3   liu_2018     63290        1.0   88.0   9522866    False     12   \n",
       "63287_T13R3   liu_2018     63287        2.0   96.0  12370157    False     13   \n",
       "63284_T14R3   liu_2018     63284        3.0  104.0  10970735    False     14   \n",
       "63293_T15R3   liu_2018     63293        1.0  112.0  13244720    False     15   \n",
       "\n",
       "             replicate batch  \n",
       "data_id                       \n",
       "S1a                  1     0  \n",
       "S1b                  2     0  \n",
       "S2a                  1     0  \n",
       "S2b                  2     0  \n",
       "S3a                  1     0  \n",
       "...                ...   ...  \n",
       "63275_T11R3          3     1  \n",
       "63290_T12R3          3     1  \n",
       "63287_T13R3          3     1  \n",
       "63284_T14R3          3     1  \n",
       "63293_T15R3          3     1  \n",
       "\n",
       "[66 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adDs_combined.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c25522-88eb-45f9-ad91-61a50ad6cd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66 × 19393\n",
       "    obs: 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control', 'order', 'replicate', 'batch'\n",
       "    var: 'gene_id', 'token_id', 'Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'gene_version', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'tag', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version', 'transcript_support_level', 'ensembl_id'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adDs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd7c307-ae07-4097-9937-10dfef98f444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66 × 19393\n",
       "    obs: 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control'\n",
       "    var: 'gene_id', 'token_id', 'Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'gene_version', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'tag', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version', 'transcript_support_level', 'ensembl_id'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the size of the remerged ann data object is compatible with the size of Cooper's\n",
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9558244-c19d-426f-8f55-b7d55922776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad\"\n",
    "adDs_combined.write(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14aea4-c699-43ff-bc1a-e78ab5b8d56b",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00f9430-2741-470b-95e0-8e64cbd13ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "from geneformer import TranscriptomeTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aaec7ff-d4b1-498d-936b-2cfd04e46ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ef2857-3362-49b1-996b-23aee0e13b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch': 'batch',\n",
       " 'control': 'control',\n",
       " 'data_id': 'data_id',\n",
       " 'dataset': 'dataset',\n",
       " 'hour': 'hour',\n",
       " 'n_counts': 'n_counts',\n",
       " 'order': 'order',\n",
       " 'replicate': 'replicate',\n",
       " 'sample_id': 'sample_id',\n",
       " 'timepoint': 'timepoint'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = os.path.dirname(input_path)\n",
    "output_path = \"/scratch/indikar_root/indikar1/cstansbu/geneformer/\"\n",
    "prefix = \"test\"\n",
    "\n",
    "def get_attributes(h5ad_path):\n",
    "    \"\"\"\n",
    "    Extracts attribute names from the `.obs` field of an h5ad AnnData file,\n",
    "    returning them as a dictionary with keys and values being the attribute names.\n",
    "\n",
    "    Args:\n",
    "        h5ad_path (str): The path to the h5ad file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys and values are the unique attribute names \n",
    "              found in the `.obs` field of the h5ad file.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5ad_path, mode=\"r\") as store:\n",
    "        attribute_names = list(store[\"obs\"].keys())\n",
    "\n",
    "    attribute_name_dict = {name: name for name in attribute_names}  # Create dictionary\n",
    "    return attribute_name_dict\n",
    "    \n",
    "\n",
    "custom_attr_name_dict = get_attributes(input_path)\n",
    "custom_attr_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556282ab-75cb-498f-86e9-a9caea53d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gene_median_dict(gene_median_file):\n",
    "    \"\"\"\n",
    "    Loads a gene median dictionary from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        gene_median_file (str): Path to the pickle file containing the gene median dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping gene IDs to their median expression values.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(gene_median_file, \"rb\") as f:\n",
    "        gene_median_dict = pickle.load(f)\n",
    "\n",
    "    return gene_median_dict\n",
    "\n",
    "\n",
    "def load_gene_tokenization(token_dictionary_file):\n",
    "    \"\"\"\n",
    "    Loads gene tokenization data from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        token_dictionary_file (str): Path to the pickle file containing the gene-token dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: Gene-token dictionary (Ensembl ID: token).\n",
    "        list: List of all gene keys (Ensembl IDs).\n",
    "        dict: Dictionary mapping gene keys to True (used for selecting genes later).\n",
    "    \"\"\"\n",
    "\n",
    "    with open(token_dictionary_file, \"rb\") as f:\n",
    "        gene_token_dict = pickle.load(f)\n",
    "\n",
    "    gene_keys = list(gene_token_dict.keys())\n",
    "\n",
    "    # Optimization: Pre-allocate the list for slight performance improvement\n",
    "    genelist_dict = dict.fromkeys(gene_keys, True)\n",
    "\n",
    "    return gene_token_dict, gene_keys, genelist_dict\n",
    "\n",
    "\n",
    "def rank_genes(gene_vector, gene_tokens):\n",
    "    \"\"\"Ranks genes based on expression values in descending order.\n",
    "\n",
    "    Args:\n",
    "        gene_vector (numpy.ndarray): Array of gene expression values.\n",
    "        gene_tokens (numpy.ndarray): Array of corresponding gene tokens.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of gene tokens sorted by descending expression value.\n",
    "    \"\"\"\n",
    "    return gene_tokens[np.argsort(-gene_vector)]\n",
    "\n",
    "\n",
    "def normalize_counts(adata_chunk,  counts_column='n_counts', target_sum=10000):\n",
    "    \"\"\"Normalizes gene expression counts within a chunk of AnnData.\n",
    "\n",
    "    Args:\n",
    "        adata_chunk (AnnData): A chunk of the AnnData object containing gene expression data.\n",
    "        counts_column (str): Name of the column in `adata_chunk.obs` containing the total counts per cell.\n",
    "        target_sum (float): The desired total count per cell after normalization.\n",
    "        norm_factor_vector (numpy.ndarray): An array of normalization factors for each gene.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: A sparse matrix containing the normalized gene expression counts.\n",
    "\n",
    "    This function performs the following steps:\n",
    "        1. Extracts the total counts per cell from the specified column (`counts_column`).\n",
    "        2. Normalizes the gene expression matrix (`adata_chunk.X`) by dividing by the total counts \n",
    "           and multiplying by the `target_sum`.\n",
    "        3. Further adjusts the normalized values by dividing by the gene-specific normalization \n",
    "           factors (`norm_factor_vector`).\n",
    "        4. Returns the normalized expression matrix as a sparse CSR matrix for efficient storage \n",
    "           and computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_counts = adata_chunk.obs[counts_column].values[:, None]  # Cell counts as column vector\n",
    "    X_norm = adata_chunk.X / n_counts * target_sum / norm_factor_vector\n",
    "    return sp.csr_matrix(X_norm)  # Efficient sparse representation\n",
    "\n",
    "\n",
    "def tokenize_anndata(adata, genelist_dict, gene_median_dict, \n",
    "                     chunk_size=100000, target_sum=10000):\n",
    "    \"\"\"\n",
    "    Tokenizes and ranks genes within an AnnData object, optimizing for memory efficiency.\n",
    "\n",
    "    This function processes gene expression data in chunks, applies normalization, and ranks genes\n",
    "    for each cell based on their expression levels. The resulting tokenized and ranked gene\n",
    "    representations, along with cell metadata, are returned.\n",
    "\n",
    "    Args:\n",
    "        adata (AnnData): The AnnData object containing gene expression data.\n",
    "        genelist_dict (dict): Dictionary mapping gene IDs to boolean values indicating relevance.\n",
    "        gene_median_dict (dict): Dictionary mapping gene IDs to their median expression values.\n",
    "        chunk_size (int, optional): Number of cells to process in each chunk (default: 1000).\n",
    "        target_sum (int, optional): Target sum for count normalization (default: 10000).\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - list: List of tokenized and ranked gene lists for each cell.\n",
    "            - dict: Dictionary containing cell metadata (keys are metadata column names).\n",
    "    \"\"\"\n",
    "    # Filter relevant miRNAs\n",
    "    coding_miRNA_mask = np.array([genelist_dict.get(i, False) for i in adata.var['ensembl_id']])\n",
    "    coding_miRNA_loc = np.where(coding_miRNA_mask)[0]\n",
    "\n",
    "    # Extract miRNA information\n",
    "    coding_miRNA_ids = adata.var['ensembl_id'][coding_miRNA_loc]\n",
    "    norm_factor_vector = np.array([gene_median_dict[i] for i in coding_miRNA_ids])\n",
    "    coding_miRNA_tokens = np.array([gene_token_dict[i] for i in coding_miRNA_ids])\n",
    "\n",
    "    tokenized_cells = []\n",
    "    file_cell_metadata = {k: [] for k in adata.obs.columns}  # Initialize metadata dict\n",
    "\n",
    "    # Process in chunks for memory efficiency\n",
    "    for chunk_start in range(0, adata.shape[0], chunk_size):\n",
    "        chunk_end = chunk_start + chunk_size\n",
    "        adata_chunk = adata[chunk_start:chunk_end, coding_miRNA_loc]\n",
    "        \n",
    "        # Normalize counts (could be replaced with the untested function above)\n",
    "        n_counts = adata_chunk.obs['n_counts'].values[:, None]\n",
    "        X_norm = adata_chunk.X / n_counts * target_sum / norm_factor_vector\n",
    "        X_norm = sp.csr_matrix(X_norm)  \n",
    "\n",
    "        # Tokenize and rank genes for each cell in chunk\n",
    "        for i in range(X_norm.shape[0]):\n",
    "            ranks = rank_genes(X_norm[i].data, coding_miRNA_tokens[X_norm[i].indices])\n",
    "            ranks = list(ranks[~np.isnan(ranks)].astype(int))\n",
    "\n",
    "            tokenized_cells.append(ranks)\n",
    "\n",
    "        # Update metadata\n",
    "        for k in adata.obs.columns:\n",
    "            file_cell_metadata[k].extend(adata_chunk.obs[k].tolist())\n",
    "\n",
    "    return tokenized_cells, file_cell_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ff49975-c812-4533-be48-7709847c1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TOKEN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/token_dictionary.pkl\"\n",
    "DEFAULT_MEDIAN_PATH = \"/nfs/turbo/umms-indikar/shared/projects/geneformer/geneformer/gene_median_dictionary.pkl\"\n",
    "\n",
    "gene_token_dict, gene_keys, genelist_dict = load_gene_tokenization(DEFAULT_TOKEN_PATH)\n",
    "gene_median_dict = load_gene_median_dict(DEFAULT_MEDIAN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ab080c-22de-4474-86ce-71274d3d29b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/anndata/__init__.py:55: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 66 × 19393 backed at '/nfs/turbo/umms-indikar/shared/projects/geneformer/data/rajapakse_lab_data_jpic.h5ad'\n",
       "    obs: 'dataset', 'sample_id', 'timepoint', 'hour', 'n_counts', 'control', 'order', 'replicate', 'batch'\n",
       "    var: 'gene_id', 'token_id', 'Chromosome', 'Source', 'Feature', 'Start', 'End', 'Score', 'Strand', 'Frame', 'gene_version', 'gene_source', 'gene_biotype', 'transcript_id', 'transcript_version', 'transcript_name', 'transcript_source', 'transcript_biotype', 'tag', 'ccds_id', 'exon_number', 'exon_id', 'exon_version', 'protein_id', 'protein_version', 'transcript_support_level', 'ensembl_id'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_path)\n",
    "adata = ad.read(input_path, backed=\"r\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca81f10-1dbe-4758-92eb-9afd5b06328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_cells, cell_metadata = tokenize_anndata(adata, \n",
    "                                                  genelist_dict, \n",
    "                                                  gene_median_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92802a06-bec1-4629-aa0e-adc5882fcdca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (66,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_cells\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (66,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.array(tokenized_cells).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ee505f2-7470-4b21-805b-efd87e015225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>hour</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>control</th>\n",
       "      <th>order</th>\n",
       "      <th>replicate</th>\n",
       "      <th>batch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7901832</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S1b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8113329</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9831046</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S2b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10123271</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chen_2015</td>\n",
       "      <td>S3a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10490839</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13515971</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9522866</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>12370157</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63284</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10970735</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>liu_2018</td>\n",
       "      <td>63293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13244720</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset sample_id  timepoint   hour  n_counts  control  order  \\\n",
       "0   chen_2015       S1a        0.0    0.0   7901832     True      1   \n",
       "1   chen_2015       S1b        0.0    0.0   8113329     True      1   \n",
       "2   chen_2015       S2a        0.0    0.0   9831046    False      2   \n",
       "3   chen_2015       S2b        0.0    0.0  10123271    False      2   \n",
       "4   chen_2015       S3a        1.0    8.0  10490839    False      3   \n",
       "..        ...       ...        ...    ...       ...      ...    ...   \n",
       "61   liu_2018     63275        3.0   80.0  13515971    False     11   \n",
       "62   liu_2018     63290        1.0   88.0   9522866    False     12   \n",
       "63   liu_2018     63287        2.0   96.0  12370157    False     13   \n",
       "64   liu_2018     63284        3.0  104.0  10970735    False     14   \n",
       "65   liu_2018     63293        1.0  112.0  13244720    False     15   \n",
       "\n",
       "    replicate batch  \n",
       "0           1     0  \n",
       "1           2     0  \n",
       "2           1     0  \n",
       "3           2     0  \n",
       "4           1     0  \n",
       "..        ...   ...  \n",
       "61          3     1  \n",
       "62          3     1  \n",
       "63          3     1  \n",
       "64          3     1  \n",
       "65          3     1  \n",
       "\n",
       "[66 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cell_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
